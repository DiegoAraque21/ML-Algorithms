{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Fundamentos de Aprendizaje Automático**\n",
    "### Universidad Autónoma de Madrid, Escuela Politécnica Superior\n",
    "### Grado en Ingeniería Informática, 4º curso\n",
    "# **Práctica 1: Naive Bayes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autores:  \n",
    "Diego Araque Fernández  \n",
    "Angela Valderrama Ricaldi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción\n",
    "\n",
    "Esta práctica consta de dos apartados relacionados con la clasificación Naive Bayes. En el primer apartado, se implemente nuestra propia versión del clasificador, considerando la opción de aplicar la corrección de Laplace. En el segundo apartado, se utiliza la implementación de Naive Bayes de la librería scikit-learn. El objetivo de esta práctica es comparar los resultados obtenidos en ambos apartados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Naive-Bayes propio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La clase abstracta Clasificador define la interfaz a seguir de los diferentes clasificadores que se implementarán a lo largo de las siguientes prácticas. En este caso, se implementa la clase ClasificadorNaiveBayes, que hereda de Clasificador y que tendrá que implementar los métodos entrenamiento y clasifica.\n",
    "\n",
    "Como ya sabemos, Naive Bayes supone que los atributos son independientes entre sí y la regla de clasificación es la siguiente:\n",
    "\n",
    "$$C_{MAP} = \\underset{C_i}{\\operatorname{argmax}} P(C_i) \\prod_{j=1}^{n} P(A_j|C_i)$$\n",
    "\n",
    "siendo $C_{MAP}$ la clase que maximiza la probabilidad a posteriori, $P(C_i)$ la probabilidad a priori de la clase $C_i$ y $P(A_j|C_i)$ la probabilidad condicionada de que el atributo $A_j$ pertenezca a la clase $C_i$.\n",
    "\n",
    "Distinguimos dos métodos abstractos en la clase Clasificador: entrenamiento y clasifica. El método entrenamiento se encarga de entrenar el clasificador, es decir, de calcular las probabilidades de que un ejemplo pertenezca a cada una de las clases (prioris). El método clasifica se encarga de clasificar un ejemplo, es decir, de asignarle una clase determinada (posteriori).\n",
    "\n",
    "Para el clasificador Naive Bayes, el método _entrenamiento()_ calcula las probabilidades a priori de cada clase con el conjunto de datos de entrenamiento. Para ello, se calcula el número de ejemplos de cada clase y se divide entre el número total de ejemplos:\n",
    "\n",
    "$$P(C_i) = \\frac{N_i}{N}$$\n",
    "\n",
    "Este valor coincide con la frecuencia relativa de cada clase. Además, se calculan las verosimilitudes de cada atributo para cada clase, es decir, las probabilidades condicionadas de cada atributo para cada clase:\n",
    "\n",
    "$$P(A_j|C_i) = \\frac{N_{ij}}{N_i}$$\n",
    "\n",
    "En los dos datasets que tenemos: ***Tic-Tac-Toe*** y ***Heart***, nos encontramos con atributos nominales y numéricos. Según el teorema de Bayes, para calcular las verosimilitudes de un atributo nominal, se calcula la frecuencia relativa de dicho atributo para cada clase como en la fórmula anterior.\n",
    "\n",
    "Puede darse el caso en el que no hay ocurrencias de un atributo para una clase determinada. En ese caso, la probabilidad condicionada de dicho atributo para esa clase será 0, lo que hará que la probabilidad a posteriori de esa clase sea 0 y se descarte como posible clase para el ejemplo a clasificar. Para evitar esto, se permite el uso de la corrección de Laplace con el argumento `laplace` al inicializar el clasificador. Esta corrección consiste en sumar 1 al numerador y el número de valores que puede tomar el atributo al denominador de la fórmula anterior:\n",
    "\n",
    "$$P(A_j|C_i) = \\frac{N_{ij} + 1}{N_i + n}$$\n",
    "\n",
    "siendo $n$ el número de valores que puede tomar el atributo $A_j$.\n",
    "\n",
    "En cambio, para los atributos numéricos, se asume que estos siguen una distribución normal, por lo que será necesario calcular la media y la desvicación típica de cada atributo para cada clase:\n",
    "\n",
    "$$\\mu_{ij} = \\frac{\\sum_{k=1}^{N_i} A_{ijk}}{N_i}$$\n",
    "\n",
    "$$\\sigma_{ij} = \\sqrt{\\frac{\\sum_{k=1}^{N_i} (A_{ijk} - \\mu_{ij})^2}{N_i}}$$\n",
    "\n",
    "siendo $A_{ijk}$ el valor del atributo $A_j$ del ejemplo $k$ de la clase $C_i$.\n",
    "\n",
    "En el método _clasifica()_, se calcula la probabilidad a posteriori de cada clase para el ejemplo a clasificar, y se calcula la clase que maximiza dicha probabilidad con el conjunto de datos de test. Para el caso de los atributos nominales, el cálculo de la probabilidad a posteriori es el siguiente:\n",
    "\n",
    "$$P(C_i|A_1, ..., A_n) = \\frac{P(C_i) \\prod_{j=1}^{n} P(A_j|C_i)}{\\sum_{k=1}^{m} P(C_k) \\prod_{j=1}^{n} P(A_j|C_k)}$$\n",
    "\n",
    "\n",
    "\n",
    "En cambio, para los atributos numéricos, su verosimilitud se calcula con la función de densidad de la distribución normal con la media y la desviación típica calculadas en el método _entrenamiento()_ y el conjunto de datos de test:\n",
    "\n",
    "$$P(A_j|C_i) = \\frac{1}{\\sqrt{2\\pi\\sigma_{ij}^2}}e^{-\\frac{(A_j - \\mu_{ij})^2}{2\\sigma_{ij}^2}}$$\n",
    "\n",
    "siendo $\\mu_{ij}$ y $\\sigma_{ij}$ la media y la desviación típica del atributo $A_j$ para la clase $C_i$.\n",
    "\n",
    "Para ese cómputo, hemos hecho uso de la función _norm.pdf()_ de la librería _scipy.stats_ que nos permite calcular la función de densidad de la distribución normal. El cálculo de las probabilidades a posteriori se realiza igual que en el caso de los atributos nominales.\n",
    "\n",
    "Por último, la predicción de la clase se guarda en una lista que se devuelve al final del método y se calcula con la función _argmax()_ de la librería _numpy_ como indica la fórmula del clasificador Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez tenemos las predicciones, es necesario validar el correcto funcionamiento del clasificador. Por ello, mediante los métodos _validacion()_ y _error()_ de la clase _Clasificador_, se calcula la tasa de fallo del clasificador. Para ello, se compara la clase predicha con la clase real del ejemplo y se calcula la tasa de acierto como el número de aciertos entre el número total de ejemplos y la tasa de error como el complementario de la tasa de acierto:\n",
    "\n",
    "$$Tasa\\ de\\ error = 1 - \\frac{N_{aciertos}}{N}$$\n",
    "\n",
    "A continuación, se muestran los resultados obtenidos con el clasificador Naive Bayes propio con los datasets ***Tic-Tac-Toe*** y ***Heart*** para los diferentes tipos de particionado y con y sin corrección de Laplace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Datos import Datos\n",
    "from EstrategiaParticionado import ValidacionSimple, ValidacionCruzada\n",
    "from Clasificador import ClasificadorNaiveBayes\n",
    "import numpy as np\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tic-Tac-Toe Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los datos\n",
    "d1=Datos('./datasets/tic-tac-toe.csv')\n",
    "d2=Datos('./datasets/heart.csv')\n",
    "\n",
    "# Creamos el clasificador Naive Bayes (sin correccion de Laplace)\n",
    "nb=ClasificadorNaiveBayes(laplace=False)\n",
    "\n",
    "# Validacion simple\n",
    "vs = ValidacionSimple(3, 0.3)\n",
    "\n",
    "# Validacion cruzada\n",
    "vc = ValidacionCruzada(10)\n",
    "\n",
    "errorvs = nb.validacion(vs, d1, nb)\n",
    "errorvc = nb.validacion(vc, d1, nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el clasificador Naive Bayes (con correccion de Laplace)\n",
    "nb_laplace=ClasificadorNaiveBayes(laplace=True)\n",
    "\n",
    "# Validacion simple\n",
    "vs_laplace = ValidacionSimple(3, 0.3)\n",
    "\n",
    "# Validacion cruzada\n",
    "vc_laplace = ValidacionCruzada(10)\n",
    "\n",
    "errorvs_laplace = nb_laplace.validacion(vs_laplace, d1, nb_laplace)\n",
    "errorvc_laplace = nb_laplace.validacion(vc_laplace, d1, nb_laplace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla de errores - Tic Tac Toe\n",
      "╒════════════════════╤══════════╤═══════════╤══════════════════╤═════════════════╕\n",
      "│                    │     Mean │       Std │   Mean (Laplace) │   Std (Laplace) │\n",
      "╞════════════════════╪══════════╪═══════════╪══════════════════╪═════════════════╡\n",
      "│ Validacion Simple  │ 0.340302 │ 0.0156687 │         0.326365 │      0.00914519 │\n",
      "├────────────────────┼──────────┼───────────┼──────────────────┼─────────────────┤\n",
      "│ Validacion Cruzada │ 0.346623 │ 0.0419577 │         0.34648  │      0.0382972  │\n",
      "╘════════════════════╧══════════╧═══════════╧══════════════════╧═════════════════╛\n"
     ]
    }
   ],
   "source": [
    "# print error comparison between laplace and non-laplace in a table using tabulate\n",
    "table = [[\"Validacion Simple\", np.mean(errorvs), np.std(errorvs), np.mean(errorvs_laplace), np.std(errorvs_laplace)],\n",
    "            [\"Validacion Cruzada\", np.mean(errorvc), np.std(errorvc), np.mean(errorvc_laplace), np.std(errorvc_laplace)]]\n",
    "print(\"Tabla de errores - Tic Tac Toe\")\n",
    "print(tabulate(table, headers=[\"\", \"Mean\", \"Std\", \"Mean (Laplace)\", \"Std (Laplace)\"], tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar en la tabla anterior, el clasificador Naive Bayes propio obtiene mejores resultados con el particionado de validación simple que con el particionado de validación cruzada. Esto se debe a que el particionado de validación cruzada divide el conjunto de datos en $k$ subconjuntos de igual tamaño, por lo que el número de ejemplos de cada clase en cada subconjunto puede variar. En cambio, el particionado de validación simple divide el conjunto de datos en dos subconjuntos, uno de entrenamiento y otro de test con un 70% y un 30% de los ejemplos respectivamente, por lo que el número de ejemplos de cada clase en cada subconjunto puede ser más similar.\n",
    "\n",
    "Por otro lado, los valores obtenidos con la corrección de Laplace son mejores que los obtenidos sin ella. Esto se debe a que, al aplicar la corrección de Laplace, se evita que la probabilidad a posteriori de una clase sea 0, lo que haría que se descartara como posible clase para el ejemplo a clasificar. Con lo cual, al aplicar la corrección de Laplace tenemos en cuenta todos los ejemplos de entrenamiento, lo que hace que el clasificador sea más preciso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los datos\n",
    "d2=Datos('./datasets/heart.csv')\n",
    "\n",
    "# Creamos el clasificador Naive Bayes (sin correccion de Laplace)\n",
    "nb=ClasificadorNaiveBayes(laplace=False)\n",
    "\n",
    "# Validacion simple\n",
    "vs = ValidacionSimple(3, 0.3)\n",
    "\n",
    "# Validacion cruzada\n",
    "vc = ValidacionCruzada(10)\n",
    "\n",
    "errorvs = nb.validacion(vs, d1, nb)\n",
    "errorvc = nb.validacion(vc, d1, nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el clasificador Naive Bayes (con correccion de Laplace)\n",
    "nb_laplace=ClasificadorNaiveBayes(laplace=True)\n",
    "\n",
    "# Validacion simple\n",
    "vs_laplace = ValidacionSimple(3, 0.3)\n",
    "\n",
    "# Validacion cruzada\n",
    "vc_laplace = ValidacionCruzada(10)\n",
    "\n",
    "errorvs_laplace = nb_laplace.validacion(vs_laplace, d1, nb_laplace)\n",
    "errorvc_laplace = nb_laplace.validacion(vc_laplace, d1, nb_laplace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla de errores - Heart\n",
      "╒════════════════════╤══════════╤═══════════╤══════════════════╤═════════════════╕\n",
      "│                    │     Mean │       Std │   Mean (Laplace) │   Std (Laplace) │\n",
      "╞════════════════════╪══════════╪═══════════╪══════════════════╪═════════════════╡\n",
      "│ Validacion Simple  │ 0.324042 │ 0.0102576 │         0.351916 │       0.0186555 │\n",
      "├────────────────────┼──────────┼───────────┼──────────────────┼─────────────────┤\n",
      "│ Validacion Cruzada │ 0.346502 │ 0.0510728 │         0.346502 │       0.0475715 │\n",
      "╘════════════════════╧══════════╧═══════════╧══════════════════╧═════════════════╛\n"
     ]
    }
   ],
   "source": [
    "# print error comparison between laplace and non-laplace in a table using tabulate\n",
    "\n",
    "table = [[\"Validacion Simple\", np.mean(errorvs), np.std(errorvs), np.mean(errorvs_laplace), np.std(errorvs_laplace)],\n",
    "            [\"Validacion Cruzada\", np.mean(errorvc), np.std(errorvc), np.mean(errorvc_laplace), np.std(errorvc_laplace)]]\n",
    "print(\"Tabla de errores - Heart\")\n",
    "print(tabulate(table, headers=[\"\", \"Mean\", \"Std\", \"Mean (Laplace)\", \"Std (Laplace)\"], tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Según los valores obtenidos, podemos observar que la tasa de error para la validación cruzada es menor que para la validación simple. Esto se debe a que el conjunto de datos es más grande que el del dataset anterior, por lo que el particionado de validación cruzada es más preciso que el de validación simple.\n",
    "\n",
    "En cambio, este dataset no está compuesto puramente de atributos nominales, sino que también tiene atributos numéricos. Se puede apreciar que los resultados obtenidos con la corrección de Laplace no mejoran los resultados obtenidos sin ella. Podemos deducir que es debido a que las probabilidades posterioris de los atributos numéricos se calculan suponiendo que siguen una distribución normal que no tiene por qué ser cierta, sino que es una aproximación. Por ello, la aplicación de la corrección de Laplace a algunos atributos nominales puede mejorar los resultados, pero no a los atributos numéricos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Naive-Bayes con Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección compararemos diferentes funciones de Naive Bayes ofrecidas por Sckikit-Learn, para ver cual modelo trabaja de mejor forma con los datasets de Tic-Tac-Toe y Heart. Y haremos comparaciones usando un encoder y diferentes validaciones. Para facilitar las comparaciones utilizaremos tablas, en las cuales podremos observar los datos the puntaje, error y desviación tipica.\n",
    "\n",
    "Las funciones a utilizar de Scikit-Learn son:\n",
    "\n",
    "* GaussianNB: Gaussian Naive Bayes.\n",
    "* MultinomialNB: Naive Bayes multinomial.\n",
    "* CategoricalNB: Categorical Naive Bayes. \n",
    "* train_test_split: Particionado de Validación Simple.\n",
    "* KFold: Particionado de Validación Cruzada.\n",
    "* OneHotEncoder: Codificación de atributos nominales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, CategoricalNB\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tic-Tac-Toe Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = d1.datos.iloc[:, :-1].to_numpy()\n",
    "\n",
    "y = d1.datos.iloc[:, -1].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GaussianNB, MultinomialNB, CategoricalNB con Validación Simple y Cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla de Sklearn - Tic-Tac Toe\n",
      "╒════════════════════╤══════════╤══════════════╤════════════╕\n",
      "│                    │    Score │   Error Rate │        Std │\n",
      "╞════════════════════╪══════════╪══════════════╪════════════╡\n",
      "│ GaussianNB         │ 0.717593 │     0.282407 │ 0.00911344 │\n",
      "├────────────────────┼──────────┼──────────────┼────────────┤\n",
      "│ MultinomialNB      │ 0.665509 │     0.334491 │ 0.0163682  │\n",
      "├────────────────────┼──────────┼──────────────┼────────────┤\n",
      "│ CategoricalNB      │ 0.695602 │     0.304398 │ 0.0360101  │\n",
      "├────────────────────┼──────────┼──────────────┼────────────┤\n",
      "│ GaussianNB (CV)    │ 0.712982 │     0.287018 │ 0.0264506  │\n",
      "├────────────────────┼──────────┼──────────────┼────────────┤\n",
      "│ MultinomialNB (CV) │ 0.657621 │     0.342379 │ 0.0172653  │\n",
      "├────────────────────┼──────────┼──────────────┼────────────┤\n",
      "│ CategoricalNB (CV) │ 0.697292 │     0.302708 │ 0.0416086  │\n",
      "╘════════════════════╧══════════╧══════════════╧════════════╛\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Gaussiano\n",
    "gnb = GaussianNB()\n",
    "gnb_errors = []\n",
    "gnb_scores = []\n",
    "\n",
    "num_samples = 3\n",
    "\n",
    "for i in range(num_samples):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    gnb.fit(X_train, y_train)\n",
    "    accuracy = gnb.score(X_test, y_test)\n",
    "    gnb_scores.append(accuracy)\n",
    "    error = 1 - accuracy\n",
    "    gnb_errors.append(error)\n",
    "\n",
    "score_gnb = np.mean(gnb_scores)\n",
    "error_rate_gnb = np.mean(gnb_errors)\n",
    "std_gnb = np.std(gnb_errors)\n",
    "\n",
    "# Naive Bayes Multinomial\n",
    "mnb = MultinomialNB()\n",
    "mnb_errors = []\n",
    "mnb_scores = []\n",
    "\n",
    "for i in range(num_samples):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    mnb.fit(X_train, y_train)\n",
    "    accuracy = mnb.score(X_test, y_test)\n",
    "    error = 1 - accuracy\n",
    "    mnb_errors.append(error)\n",
    "    mnb_scores.append(accuracy)\n",
    "\n",
    "score_mnb = np.mean(mnb_scores)\n",
    "error_rate_mnb = np.mean(mnb_errors)\n",
    "std_mnb = np.std(mnb_errors)\n",
    "\n",
    "# Naive Bayes Categorico\n",
    "cnb = CategoricalNB()\n",
    "cnb_errors = []\n",
    "cnb_scores = []\n",
    "\n",
    "for i in range(num_samples):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    cnb.fit(X_train, y_train)\n",
    "    accuracy = cnb.score(X_test, y_test)\n",
    "    cnb_scores.append(accuracy)\n",
    "    error = 1 - accuracy\n",
    "    cnb_errors.append(error)\n",
    "\n",
    "score_cnb = np.mean(cnb_scores)\n",
    "error_rate_cnb = np.mean(cnb_errors)\n",
    "std_cnb = np.std(cnb_errors)\n",
    "# Uso de validación cruzada\n",
    "\n",
    "# numero de folds definidos\n",
    "folds = 10\n",
    "kf = KFold(n_splits=folds, shuffle=True)\n",
    "\n",
    "# Crear lista para tener los puntajes de cada fold\n",
    "accuracy_scores = {\"GaussianNB\": [], \"MultinomialNB\": [], \"CategoricalNB\": []}\n",
    "# Crear lista para tener los errores de cada fold\n",
    "error_rates = {\"GaussianNB\": [], \"MultinomialNB\": [], \"CategoricalNB\": []}\n",
    "\n",
    "\n",
    "# Dividir los datos en train y test y evaluar cada fold\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train_cv, X_test_cv = X[train_index], X[test_index]\n",
    "    y_train_cv, y_test_cv = y[train_index], y[test_index]\n",
    "\n",
    "    # Naive Bayes Gaussiano para validacion cruzada\n",
    "    gnb_cv = GaussianNB()\n",
    "    # Multinomial Naive Bayes para validacion cruzada\n",
    "    mnb_cv = MultinomialNB()\n",
    "    # Categorical Naive Bayes para validacion cruzada\n",
    "    cnb_cv = CategoricalNB()\n",
    "\n",
    "    # Entrenar los modelos\n",
    "    gnb_cv.fit(X_train_cv, y_train_cv)\n",
    "    mnb_cv.fit(X_train_cv, y_train_cv)\n",
    "    cnb_cv.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "    # prediction\n",
    "    y_pred_cv_gnb = gnb_cv.predict(X_test_cv)\n",
    "    y_pred_cv_mnb = mnb_cv.predict(X_test_cv)\n",
    "    y_pred_cv_cnb = cnb_cv.predict(X_test_cv)\n",
    "\n",
    "    # Obtener los puntajes\n",
    "    accuracy_scores[\"GaussianNB\"].append(accuracy_score(y_test_cv, y_pred_cv_gnb))\n",
    "    accuracy_scores[\"MultinomialNB\"].append(accuracy_score(y_test_cv, y_pred_cv_mnb))\n",
    "    accuracy_scores[\"CategoricalNB\"].append(accuracy_score(y_test_cv, y_pred_cv_cnb))\n",
    "\n",
    "    # Obtener los errores\n",
    "    error_rates[\"GaussianNB\"].append(1-accuracy_score(y_test_cv, y_pred_cv_gnb))\n",
    "    error_rates[\"MultinomialNB\"].append(1-accuracy_score(y_test_cv, y_pred_cv_mnb))\n",
    "    error_rates[\"CategoricalNB\"].append(1-accuracy_score(y_test_cv, y_pred_cv_cnb))\n",
    "\n",
    "# Calcular los promedios de los puntajes, errores y desviaciones estandar\n",
    "accuracy_score_gnb_cv = np.mean(accuracy_scores[\"GaussianNB\"])\n",
    "error_rate_gnb_cv = np.mean(error_rates[\"GaussianNB\"])\n",
    "std_gnb_cv = np.std(error_rates[\"GaussianNB\"])\n",
    "\n",
    "accuracy_score_mnb_cv = np.mean(accuracy_scores[\"MultinomialNB\"])\n",
    "error_rate_mnb_cv = np.mean(error_rates[\"MultinomialNB\"])\n",
    "std_mnb_cv = np.std(error_rates[\"MultinomialNB\"])\n",
    "\n",
    "accuracy_score_cnb_cv = np.mean(accuracy_scores[\"CategoricalNB\"])\n",
    "error_rate_cnb_cv = np.mean(error_rates[\"CategoricalNB\"])\n",
    "std_cnb_cv = np.std(error_rates[\"CategoricalNB\"])\n",
    "\n",
    "# Crear tabla de comparación de resultados\n",
    "table = [[\"GaussianNB\", score_gnb, error_rate_gnb, std_gnb],\n",
    "            [\"MultinomialNB\", score_mnb, error_rate_mnb, std_mnb],\n",
    "            [\"CategoricalNB\", score_cnb, error_rate_cnb, std_cnb],\n",
    "            [\"GaussianNB (CV)\", accuracy_score_gnb_cv, error_rate_gnb_cv, std_gnb_cv],\n",
    "            [\"MultinomialNB (CV)\", accuracy_score_mnb_cv, error_rate_mnb_cv, std_mnb_cv],\n",
    "            [\"CategoricalNB (CV)\", accuracy_score_cnb_cv, error_rate_cnb_cv, std_cnb_cv]]\n",
    "\n",
    "print(\"Tabla de Sklearn - Tic-Tac Toe\")\n",
    "print(tabulate(table, headers=[\"\", \"Score\", \"Error Rate\", \"Std\"], tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente tabla se puede observar como para el dataset de Tic Tac Toe, con una validación simple se obtiene un porcentaje de error bastantes parecidos. No hay mucha variación en las predicciones de cada fold (Validación Cruzada) o iteración (Validación Simple). \n",
    "\n",
    "El modelo que esta sirviendo de mejor forma es el GaussianNB, con porcentajes de acierto de alrededor del 70%. Esto se debe principalmente que todos los datos nominales los cambiamos a numeros, lo cual permite al modelo sacar su mejor versión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usar OneHotEncoder para el mismo dataset y encontrar las diferencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer la transformación con el OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "X_hot_encoded = enc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GaussianNB, MultinomialNB, CategoricalNB con Validación Simple y Cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla de Scikit Learn con HotEncoder - Tic-Tac Toe\n",
      "╒════════════════════╤══════════╤══════════════╤════════════╕\n",
      "│                    │    Score │   Error Rate │        Std │\n",
      "╞════════════════════╪══════════╪══════════════╪════════════╡\n",
      "│ GaussianNB         │ 0.68287  │     0.31713  │ 0.00433062 │\n",
      "├────────────────────┼──────────┼──────────────┼────────────┤\n",
      "│ MultinomialNB      │ 0.719907 │     0.280093 │ 0.00163682 │\n",
      "├────────────────────┼──────────┼──────────────┼────────────┤\n",
      "│ CategoricalNB      │ 0.668981 │     0.331019 │ 0.0216531  │\n",
      "├────────────────────┼──────────┼──────────────┼────────────┤\n",
      "│ GaussianNB (CV)    │ 0.667917 │     0.332083 │ 0.0451438  │\n",
      "├────────────────────┼──────────┼──────────────┼────────────┤\n",
      "│ MultinomialNB (CV) │ 0.697127 │     0.302873 │ 0.0502824  │\n",
      "├────────────────────┼──────────┼──────────────┼────────────┤\n",
      "│ CategoricalNB (CV) │ 0.689814 │     0.310186 │ 0.0474748  │\n",
      "╘════════════════════╧══════════╧══════════════╧════════════╛\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Gaussiano\n",
    "gnb_enc = GaussianNB()\n",
    "\n",
    "enc_scores_gnb = []\n",
    "enc_errors_gnb = []\n",
    "\n",
    "for i in range(num_samples):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_hot_encoded, y, test_size=0.3)\n",
    "    gnb_enc.fit(X_train, y_train)\n",
    "    accuracy = gnb_enc.score(X_test, y_test)\n",
    "    enc_scores_gnb.append(accuracy)\n",
    "    enc_errors_gnb.append(1 - accuracy)\n",
    "\n",
    "gnb_enc_score = np.mean(enc_scores_gnb)\n",
    "gnb_enc_error_rate = np.mean(enc_errors_gnb)\n",
    "gnb_enc_std = np.std(enc_errors_gnb)\n",
    "\n",
    "# Naive Bayes Multinomial\n",
    "mnb_enc = MultinomialNB()\n",
    "\n",
    "enc_scores_mnb = []\n",
    "enc_errors_mnb = []\n",
    "\n",
    "for i in range(num_samples):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_hot_encoded, y, test_size=0.3)\n",
    "    mnb_enc.fit(X_train, y_train)\n",
    "    accuracy = mnb_enc.score(X_test, y_test)\n",
    "    enc_scores_mnb.append(accuracy)\n",
    "    enc_errors_mnb.append(1 - accuracy)\n",
    "\n",
    "mnb_enc_score = np.mean(enc_scores_mnb)\n",
    "mnb_enc_error_rate = np.mean(enc_errors_mnb)\n",
    "mnb_enc_std = np.std(enc_errors_mnb)\n",
    "\n",
    "# Naive Bayes Categorico\n",
    "cnb_enc = CategoricalNB()\n",
    "\n",
    "enc_scores_cnb = []\n",
    "enc_errors_cnb = []\n",
    "\n",
    "for i in range(num_samples):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_hot_encoded, y, test_size=0.3)\n",
    "    cnb_enc.fit(X_train, y_train)\n",
    "    accuracy = cnb_enc.score(X_test, y_test)\n",
    "    enc_scores_cnb.append(accuracy)\n",
    "    enc_errors_cnb.append(1 - accuracy)\n",
    "\n",
    "cnb_enc_score = np.mean(enc_scores_cnb)\n",
    "cnb_enc_error_rate = np.mean(enc_errors_cnb)\n",
    "cnb_enc_std = np.std(enc_errors_cnb)\n",
    "\n",
    "# Hacer Validación Cruzada\n",
    "\n",
    "# Definir el numero de folds\n",
    "folds = 10\n",
    "\n",
    "# Crear el objeto KFold\n",
    "kf = KFold(n_splits=folds, shuffle=True)\n",
    "\n",
    "# Crear diccioanrio para accuracy scores\n",
    "accuracy_scores_enc = {\"GaussianNB\": [], \"MultinomialNB\": [], \"CategoricalNB\": []}\n",
    "# Crear diccionario para errores\n",
    "error_rates_enc = {\"GaussianNB\": [], \"MultinomialNB\": [], \"CategoricalNB\": []}\n",
    "\n",
    "# Dividir folds entre train y test y evaluar cada uno\n",
    "for train_index, test_index in kf.split(X_hot_encoded):\n",
    "    X_train_cv_enc, X_test_cv_enc = X_hot_encoded[train_index], X_hot_encoded[test_index]\n",
    "    y_train_cv_enc, y_test_cv_enc = y[train_index], y[test_index]\n",
    "\n",
    "    # Crear modelo de Gaussian Naive Bayes\n",
    "    gnb_cv_enc = GaussianNB()\n",
    "\n",
    "    # Crear modelo de Multinomial Naive Bayes\n",
    "    mnb_cv_enc = MultinomialNB()\n",
    "\n",
    "    # Crear modelo de Categorical Naive Bayes\n",
    "    cnb_cv_enc = CategoricalNB()\n",
    "\n",
    "    # Entrenar los modelos\n",
    "    gnb_cv_enc.fit(X_train_cv_enc, y_train_cv_enc)\n",
    "    mnb_cv_enc.fit(X_train_cv_enc, y_train_cv_enc)\n",
    "    cnb_cv_enc.fit(X_train_cv_enc, y_train_cv_enc)\n",
    "\n",
    "    # Predecir\n",
    "    y_pred_cv_enc_gnb = gnb_cv_enc.predict(X_test_cv_enc)\n",
    "    y_pred_cv_enc_mnb = mnb_cv_enc.predict(X_test_cv_enc)\n",
    "    y_pred_cv_enc_cnb = cnb_cv_enc.predict(X_test_cv_enc)\n",
    "\n",
    "    # Obtener puntajes\n",
    "    accuracy_scores_enc[\"GaussianNB\"].append(accuracy_score(y_test_cv_enc, y_pred_cv_enc_gnb))\n",
    "    accuracy_scores_enc[\"MultinomialNB\"].append(accuracy_score(y_test_cv_enc, y_pred_cv_enc_mnb))\n",
    "    accuracy_scores_enc[\"CategoricalNB\"].append(accuracy_score(y_test_cv_enc, y_pred_cv_enc_cnb))\n",
    "\n",
    "    # Obtener Errores\n",
    "    error_rates_enc[\"GaussianNB\"].append(1-accuracy_score(y_test_cv_enc, y_pred_cv_enc_gnb))\n",
    "    error_rates_enc[\"MultinomialNB\"].append(1-accuracy_score(y_test_cv_enc, y_pred_cv_enc_mnb))\n",
    "    error_rates_enc[\"CategoricalNB\"].append(1-accuracy_score(y_test_cv_enc, y_pred_cv_enc_cnb))\n",
    "\n",
    "# Calcular promedios de puntajes, errores y desviaciones estandar\n",
    "accuracy_score_gnb_enc = np.mean(accuracy_scores_enc[\"GaussianNB\"])\n",
    "error_rate_gnb_enc = np.mean(error_rates_enc[\"GaussianNB\"])\n",
    "std_gnb_enc = np.std(error_rates_enc[\"GaussianNB\"])\n",
    "\n",
    "accuracy_score_mnb_enc = np.mean(accuracy_scores_enc[\"MultinomialNB\"])\n",
    "error_rate_mnb_enc = np.mean(error_rates_enc[\"MultinomialNB\"])\n",
    "std_mnb_enc = np.std(error_rates_enc[\"MultinomialNB\"])\n",
    "\n",
    "accuracy_score_cnb_enc = np.mean(accuracy_scores_enc[\"CategoricalNB\"])\n",
    "error_rate_cnb_enc = np.mean(error_rates_enc[\"CategoricalNB\"])\n",
    "std_cnb_enc = np.std(error_rates_enc[\"CategoricalNB\"])\n",
    "\n",
    "\n",
    "# Crear tabla de comparación de resultados\n",
    "table = [[\"GaussianNB\", gnb_enc_score, gnb_enc_error_rate, gnb_enc_std],\n",
    "            [\"MultinomialNB\", mnb_enc_score, mnb_enc_error_rate, mnb_enc_std],\n",
    "            [\"CategoricalNB\", cnb_enc_score, cnb_enc_error_rate, cnb_enc_std],\n",
    "            [\"GaussianNB (CV)\", accuracy_score_gnb_enc, error_rate_gnb_enc, std_gnb_enc],\n",
    "            [\"MultinomialNB (CV)\", accuracy_score_mnb_enc, error_rate_mnb_enc, std_mnb_enc],\n",
    "            [\"CategoricalNB (CV)\", accuracy_score_cnb_enc, error_rate_cnb_enc, std_cnb_enc]]\n",
    "\n",
    "print(\"Tabla de Scikit Learn con HotEncoder - Tic-Tac Toe\")\n",
    "print(tabulate(table, headers=[\"\", \"Score\", \"Error Rate\", \"Std\"], tablefmt=\"fancy_grid\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente tabla se puede observar como para el dataset de Tic Tac Toe, con una validación simple se obtienen porcentajes de error parecidos a los de la validación cruzada. Cuando usamos el OneHotEncoder nos fijamos que los tres modelos tienen comportamientos muy similares, donde los tres porcentajes de acierto finales (usando validación simple) rondan el 70%, siendo el modelo MultinomialNB el que obtiene un porcentaje de acierto mas alto. \n",
    "\n",
    "Cuando le aplicamos el OneHotEncoder los datos siguen siendo bastante parecidos a cuando no lo aplicamos. Las predicciones que menos varian son las de los modelos GaussianNB y MultinomialNB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = d2.datos.iloc[:, :-1].to_numpy(), d2.datos.iloc[:, -1].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GaussianNB con Validación Simple y Cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla de Sklearn Validación Simple - Heart\n",
      "╒═══════════════╤══════════╤══════════════╤═══════════╕\n",
      "│               │    Score │   Error Rate │       Std │\n",
      "╞═══════════════╪══════════╪══════════════╪═══════════╡\n",
      "│ GaussianNB    │ 0.847826 │     0.152174 │ 0.0242149 │\n",
      "├───────────────┼──────────┼──────────────┼───────────┤\n",
      "│ GaussianNB CV │ 0.712982 │     0.287018 │ 0.0264506 │\n",
      "╘═══════════════╧══════════╧══════════════╧═══════════╛\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Gaussiano\n",
    "gnb_heart = GaussianNB()\n",
    "\n",
    "gnb_heart_scores = []\n",
    "gnb_heart_errors = []\n",
    "\n",
    "for i in range(num_samples):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    gnb_heart.fit(X_train, y_train)\n",
    "    accuracy = gnb_heart.score(X_test, y_test)\n",
    "    gnb_heart_scores.append(accuracy)\n",
    "    gnb_heart_errors.append(1 - accuracy)\n",
    "\n",
    "\n",
    "gnb_heart_score = np.mean(gnb_heart_scores)\n",
    "gnb_heart_error_rate = np.mean(gnb_heart_errors)\n",
    "gnb_heart_std = np.std(gnb_heart_errors)\n",
    "\n",
    "# Validación cruzada\n",
    "\n",
    "# Definir numero de folds\n",
    "folds = 10\n",
    "\n",
    "# Crear objeto KFold\n",
    "kf_heart = KFold(n_splits=folds, shuffle=True)\n",
    "\n",
    "# Crear lista para accuracy scores\n",
    "accuracy_scores_heart = {\"GaussianNB\": []}\n",
    "\n",
    "# Crear lista para errores\n",
    "error_rates_heart = {\"GaussianNB\": []}\n",
    "\n",
    "# Dividir los datos en train y test y evaluar cada fold\n",
    "for train_index, test_index in kf.split(X):\n",
    "\n",
    "    X_train_cv_heart, X_test_cv_heart = X[train_index], X[test_index]\n",
    "    y_train_cv_heart, y_test_cv_heart = y[train_index], y[test_index]\n",
    "\n",
    "    # Crear modelo de Gaussian Naive Bayes\n",
    "    gnb_cv_heart = GaussianNB()\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    gnb_cv_heart.fit(X_train_cv_heart, y_train_cv_heart)\n",
    "\n",
    "    # Predecir\n",
    "    y_pred_cv_heart_gnb = gnb_cv_heart.predict(X_test_cv_heart)\n",
    "\n",
    "    # Obtenemos puntajes\n",
    "    accuracy_scores_heart[\"GaussianNB\"].append(accuracy_score(y_test_cv_heart, y_pred_cv_heart_gnb))\n",
    "\n",
    "    # Obtenemos errores\n",
    "    error_rates_heart[\"GaussianNB\"].append(1-accuracy_score(y_test_cv_heart, y_pred_cv_heart_gnb))\n",
    "\n",
    "\n",
    "# Calcular promedios de puntajes, errores y desviaciones estandar\n",
    "accuracy_score_gnb_heart = np.mean(accuracy_scores[\"GaussianNB\"])\n",
    "error_rate_gnb_heart = np.mean(error_rates[\"GaussianNB\"])\n",
    "std_gnb_heart = np.std(error_rates[\"GaussianNB\"])\n",
    "\n",
    "# Crear tabla de comparación de resultados\n",
    "table = [[\"GaussianNB\", gnb_heart_score, gnb_heart_error_rate, gnb_heart_std], \n",
    "            [\"GaussianNB CV\", accuracy_score_gnb_heart, error_rate_gnb_heart, std_gnb_heart]]\n",
    "\n",
    "print(\"Tabla de Sklearn Validación Simple - Heart\")\n",
    "print(tabulate(table, headers=[\"\", \"Score\", \"Error Rate\", \"Std\"], tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este dataset, solo usamos el modelo GaussianNB, ya que es el único que nos permite trabajar con atributos numéricos. MultinomialNB y CategoricalNB trabajan con atributos nominales, por lo tanto su uso no es adecuado para este dataset. Para poder hacer uso de estos modelos, sería necesario discretizar los atributos numéricos, pero con ello perderíamos información y precisión.\n",
    "\n",
    "En la tabla, podemos observar como la tasa de error es mucho menor usando el tipo de particionado de Validación Simple que con el de Validación Cruzada. Esto se debe a que el dataset no es muy grande, y al hacer el particionado en k folds, podemos estar teniendo muchos sesgos de información."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usar HotEncoder para el mismo dataset y revisar las diferencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hot_encoded = enc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla de Sklearn con HotEncoder - Heart\n",
      "╒═════════════════╤══════════╤══════════════╤═══════════╕\n",
      "│                 │    Score │   Error Rate │       Std │\n",
      "╞═════════════════╪══════════╪══════════════╪═══════════╡\n",
      "│ GaussianNB      │ 0.555556 │     0.444444 │ 0.0151809 │\n",
      "├─────────────────┼──────────┼──────────────┼───────────┤\n",
      "│ GaussianNB (CV) │ 0.559854 │     0.440146 │ 0.0630948 │\n",
      "╘═════════════════╧══════════╧══════════════╧═══════════╛\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Gaussiano\n",
    "gnb_heart_enc = GaussianNB()\n",
    "\n",
    "gnb_heart_enc_scores = []\n",
    "gnb_heart_enc_errors = []\n",
    "\n",
    "for i in range(num_samples):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_hot_encoded, y, test_size=0.3)\n",
    "\n",
    "    gnb_heart_enc.fit(X_train, y_train)\n",
    "\n",
    "    accuracy = gnb_heart_enc.score(X_test, y_test)\n",
    "\n",
    "    gnb_heart_enc_scores.append(accuracy)\n",
    "\n",
    "    gnb_heart_enc_errors.append(1 - accuracy)\n",
    "\n",
    "gnb_heart_enc_score = np.mean(gnb_heart_enc_scores)\n",
    "gnb_heart_enc_error_rate = np.mean(gnb_heart_enc_errors)\n",
    "gnb_heart_enc_std = np.std(gnb_heart_enc_errors)\n",
    "\n",
    "# Hacer validación cruzada\n",
    "\n",
    "# Definir numero de folds\n",
    "folds = 10\n",
    "\n",
    "# Crear objeto KFold\n",
    "kf = KFold(n_splits=folds, shuffle=True)\n",
    "\n",
    "# Crear diccionario para puntajes\n",
    "accuracy_scores_heart_enc = {\"GaussianNB\": []}\n",
    "\n",
    "# Crear diccionario para errores\n",
    "error_rates_heart_enc = {\"GaussianNB\": []}\n",
    "\n",
    "\n",
    "# Dividir los datos en train y test y evaluar cada fold\n",
    "for train_index, test_index in kf.split(X_hot_encoded):\n",
    "    X_train_cv_heart_enc, X_test_cv_heart_enc = X_hot_encoded[train_index], X_hot_encoded[test_index]\n",
    "    y_train_cv_heart_enc, y_test_cv_heart_enc = y[train_index], y[test_index]\n",
    "\n",
    "    # Crear modelo de Gaussian Naive Bayes\n",
    "    gnb_cv_heart_enc = GaussianNB()\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    gnb_cv_heart_enc.fit(X_train_cv_heart_enc, y_train_cv_heart_enc)\n",
    "\n",
    "    # Predecir\n",
    "    y_pred_cv_heart_enc_gnb = gnb_cv_heart_enc.predict(X_test_cv_heart_enc)\n",
    "\n",
    "    # Obtenemos puntajes\n",
    "    accuracy_scores_heart_enc[\"GaussianNB\"].append(accuracy_score(y_test_cv_heart_enc, y_pred_cv_heart_enc_gnb))\n",
    "\n",
    "    # Obtenemos errores\n",
    "    error_rates_heart_enc[\"GaussianNB\"].append(1-accuracy_score(y_test_cv_heart_enc, y_pred_cv_heart_enc_gnb))\n",
    "\n",
    "# Calcular promedios de puntajes, errores y desviaciones estandar\n",
    "accuracy_score_gnb_heart_enc = np.mean(accuracy_scores_heart_enc[\"GaussianNB\"])\n",
    "error_rate_gnb_heart_enc = np.mean(error_rates_heart_enc[\"GaussianNB\"])\n",
    "std_gnb_heart_enc = np.std(error_rates_heart_enc[\"GaussianNB\"])\n",
    "\n",
    "# Crear tabla de comparación de resultados\n",
    "table = [[\"GaussianNB\", gnb_heart_enc_score, gnb_heart_enc_error_rate, gnb_heart_enc_std],\n",
    "            [\"GaussianNB (CV)\", accuracy_score_gnb_heart_enc, error_rate_gnb_heart_enc, std_gnb_heart_enc]]\n",
    "\n",
    "print(\"Tabla de Sklearn con HotEncoder - Heart\")\n",
    "print(tabulate(table, headers=[\"\", \"Score\", \"Error Rate\", \"Std\"], tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al aplicar OneHotEncoder, la tasa de error disminuye para los dos tipos de estrategia de particionado, tanto en la Validación Simple y Validación Cruzada. Podríamos considerar el clasificador GaussianNB con Validación Simple, como el más preciso al tener la menor desviación. Aun así, las dos estrategias comparten la misma tasa de fallo que apenas supera el 55%.\n",
    "\n",
    "Comparado con la tabla anterior en la cual no se hace uso de la codificación, la tasa de fallo es notablemente alta. Podemos concluir que el uso del Encoder no mejora los resultados y se podría despreciar su uso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Conclusión\n",
    "\n",
    "Hemos podido comprobar en esta práctica las diferencias de implementación entre nuestro clasificador Naive Bayes y el de la librería scikit-learn. Nuestro propio clasificador no consta de las mismas funcionalidades que los métodos implementados en la librería scikit-learn pero los resultados obtenidos son ligeramente parecidas.\n",
    "\n",
    "En algunos casos, el particionado Validación Simple obtiene mejores resultados que el de Validación Cruzada, pero en otros casos ocurre lo contrario. Esto se debe a que el particionado de Validación Cruzada divide el conjunto de datos en $k$ subconjuntos de igual tamaño, por lo que el número de ejemplos de cada clase en cada subconjunto puede variar. En cambio, el particionado de Validación Simple divide el conjunto de datos en dos subconjuntos, uno de entrenamiento y otro de test con un 70% y un 30% de los ejemplos respectivamente, por lo que el número de ejemplos de cada clase en cada subconjunto puede ser más similar.\n",
    "\n",
    "Por otro lado, la aplicación de la corrección de Laplace mejora los resultados obtenidos por nuestro propio clasificador tal y como indica la teoría pero en algunos casos, su uso puede ser despreciado ya que no es una mejora significativa.\n",
    "\n",
    "En cuanto a los resultados de Scikit-Learn, debido a que su nivel de exactitud y complejidad es mayor, los resultados obtenidos son mucho más precisos que los nuestros y por ende más fiables. Las diferencias entre la Validación Simple y la Cruzada son las mismas que en nuestro clasificador, pero en este caso, la diferencia de error es mucho menor.\n",
    "\n",
    "Las diferentes pruebas realizadas con los clasificadores de Scikit-Learn nos han permitido entender las propiedades de cada uno, así como sus punto fuertes y débiles en relación al procesamiento de los datos dependiendo de si era de tipo categórico o numérico.\n",
    "\n",
    "Por último, se han aplicado estrategias de codificación que han variado los resultados para estos clasificadores, en algunos casos mejorando las predicciones y en otros empeorándolas. Esto es debido a que la codificación de los datos puede hacer que se pierda información, sobre todo, para los atributos numéricos, ya que estos se convierten en atributos nominales."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
