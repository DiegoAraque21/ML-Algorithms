{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Fundamentos de Aprendizaje Automático**\n",
    "### Universidad Autónoma de Madrid, Escuela Politécnica Superior\n",
    "### Grado en Ingeniería Informática, 4º curso\n",
    "# **Práctica 2: K-NN y K-MEANS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autores:  \n",
    "Diego Araque Fernández  \n",
    "Angela Valderrama Ricaldi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción\n",
    "\n",
    "Esta práctica consta de tres apartados relacionados con los algoritmos de clasificación K-NN y K-Means. En el primer apartado se implementa nuestro propio clasificador KNN, utilizando la distancia euclídea, normalizando o no los datos de los datasets Heart y WDBC. En el segundo apartado se implementa el algoritmo K-Means y se prueba con el dataset de Iris, donde se pueden apreciar los diferentes clusteres creados. Por último, en el tercer apartado se utiliza de la librería de Scikit-Learn el clasificador KNN y el algoritmo K-Means para comparar los resultados obtenidos con los nuestros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Clasificador K Nearest Neighbors (K-NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El clasificador K Nearest Neighbors (KNN) se ha implementado en el fichero `ClasificadorKNN.py`, siendo una clase que hereda de Clasificador y que implementa los métodos `entrenamiento` y `clasifica`.\n",
    "\n",
    "Como ya sabemos, KNN es un clasificador de aprendizaje supervisado no paramétrico, es decir, no asume nada sobre la distribución de los datos. KNN utiliza la proximidad para clasificar o predecir sobre nuevos datos. Para calcular la proximidad, es muy común utilizar la distancia euclídea, aunque también se suele hacer uso de otras distancias como la distancia de Manhattan o la distancia de Minkowski, entre otras. En nuestra implementación, hemos utilizado la distancia euclídea:\n",
    "\n",
    "$$d(x,y) = \\sqrt{\\sum_{i=1}^{n}(x_i-y_i)^2}$$\n",
    "\n",
    "donde $x$ e $y$ son dos vectores de $n$ dimensiones.\n",
    "\n",
    "El nombre de este clasificador viene dado por el hecho de que, para clasificar un nuevo dato, se calcula la distancia a los diferentes datos y se eligen los $k$ vecinos más cercanos. De estos, la clase que más aparezca entre esos datos, será la clase a asignar. Por ello, el valor de k es muy importante, ya que se puede estar sobreajustando o subajustando el modelo. Además, para evitar que haya empates, se suele elegir un valor impar para k. En nuestra implementación, se ha probado con los siguientes valores de k: 1, 3, 5, 11, 21 y 31.\n",
    "\n",
    "Nuestra implementación de KNN permite normalizar o no los datos. La normalización de los datos influye en el resultado final, estando los datos muy dispersos o no. Los únicos datos que se normalizan son los pertenecientes a atributos numéricos. Por ello, a cada dato numérico se le resta la media de todos los datos numéricos y se divide entre la desviación típica de todos los datos numéricos. La normalización se realiza en el método `entrenamiento`, ya que es necesario conocer la media y la desviación típica de los datos para poder normalizarlos. En el método `clasifica`, se normalizan los datos de test utilizando la media y la desviación típica de los datos de entrenamiento. La normalización de los datos se realiza de la siguiente manera:\n",
    "\n",
    "$$x_{norm} = \\frac{x-\\mu}{\\sigma}$$\n",
    "\n",
    "donde $x$ es el dato a normalizar, $\\mu$ es la media de los datos y $\\sigma$ es la desviación típica de los datos.\n",
    "\n",
    "Como se ha mencionado antes, la métrica a utilizar es la distancia euclídea. Normalmente, esta distancia trabaja mejor con atributos numéricos y con valores discretizados es recomendable la distancia de Hamming. En este caso, se ha utilizado la distancia euclídea para todos los atributos.\n",
    "\n",
    "En el método `clasifica`, se calcula la distancia euclídea entre el dato a clasificar y todos los datos de entrenamiento. Se ordenan las distancias de menor a mayor y se eligen los $k$ vecinos más cercanos. De estos vecinos, se elige la clase que más aparezca y se guarda la clase predicha en una lista. Por último, se devuelve la lista de clases predichas.\n",
    "\n",
    "Las pruebas del clasificador se harán con los datasets Heart y WDBC, tanto para datos normalizados como no normalizados, usando los dos tipos de estrategia de particionado y con los diferentes valores de k mencionados anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Datos import Datos\n",
    "from EstrategiaParticionado import ValidacionSimple, ValidacionCruzada\n",
    "from ClasificadorKNN import ClasificadorKNN\n",
    "from ClusteringKMeans import K_Means\n",
    "\n",
    "import numpy as np\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets to test\n",
    "heart = Datos('datasets/heart.csv')\n",
    "wdbc = Datos('datasets/wdbc.csv')\n",
    "iris = Datos('datasets/iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create classifiers with different number of neighbours (k value to test: 1, 3, 5, 11, 21, 31)\n",
    "\n",
    "# normalize data\n",
    "myknn_1 = ClasificadorKNN(k=1)\n",
    "myknn_3 = ClasificadorKNN(k=3)\n",
    "myknn_5 = ClasificadorKNN(k=5)\n",
    "myknn_11 = ClasificadorKNN(k=11)\n",
    "myknn_21 = ClasificadorKNN(k=21)\n",
    "myknn_31 = ClasificadorKNN(k=31)\n",
    "\n",
    "# do not normalize data\n",
    "not_myknn_1 = ClasificadorKNN(k=1, normalize=False)\n",
    "not_myknn_3 = ClasificadorKNN(k=3, normalize=False)\n",
    "not_myknn_5 = ClasificadorKNN(k=5, normalize=False)\n",
    "not_myknn_11 = ClasificadorKNN(k=11, normalize=False)\n",
    "not_myknn_21 = ClasificadorKNN(k=21, normalize=False)\n",
    "not_myknn_31 = ClasificadorKNN(k=31, normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hold-out validation (10 sample)\n",
    "vs = ValidacionSimple(10, 0.3)\n",
    "\n",
    "errors_vs_heart = {\"k=1\": np.array([]), \"k=3\": np.array([]), \"k=5\": np.array([]), \"k=11\": np.array([]), \"k=21\": np.array([]), \"k=31\": np.array([])}\n",
    "\n",
    "# validate classifiers with heart dataset\n",
    "errors_vs_heart[\"k=1\"] = myknn_1.validacion(vs, heart, myknn_1)\n",
    "errors_vs_heart[\"k=3\"] = myknn_3.validacion(vs, heart, myknn_3)\n",
    "errors_vs_heart[\"k=5\"] = myknn_5.validacion(vs, heart, myknn_5)\n",
    "errors_vs_heart[\"k=11\"] = myknn_11.validacion(vs, heart, myknn_11)\n",
    "errors_vs_heart[\"k=21\"] = myknn_21.validacion(vs, heart, myknn_21)\n",
    "errors_vs_heart[\"k=31\"] = myknn_31.validacion(vs, heart, myknn_31)\n",
    "\n",
    "# calculate mean accuracy\n",
    "accuracy_vs_myknn1 = np.mean(1 - np.array(errors_vs_heart[\"k=1\"]))\n",
    "accuracy_vs_myknn3 = np.mean(1 - np.array(errors_vs_heart[\"k=3\"]))\n",
    "accuracy_vs_myknn5 = np.mean(1 - np.array(errors_vs_heart[\"k=5\"]))\n",
    "accuracy_vs_myknn11 = np.mean(1 - np.array(errors_vs_heart[\"k=11\"]))\n",
    "accuracy_vs_myknn21 = np.mean(1 - np.array(errors_vs_heart[\"k=21\"]))\n",
    "accuracy_vs_myknn31 = np.mean(1 - np.array(errors_vs_heart[\"k=31\"]))\n",
    "\n",
    "# calculate mean error rate\n",
    "error_rate_vs_myknn1 = np.mean(errors_vs_heart[\"k=1\"])\n",
    "error_rate_vs_myknn3 = np.mean(errors_vs_heart[\"k=3\"])\n",
    "error_rate_vs_myknn5 = np.mean(errors_vs_heart[\"k=5\"])\n",
    "error_rate_vs_myknn11 = np.mean(errors_vs_heart[\"k=11\"])\n",
    "error_rate_vs_myknn21 = np.mean(errors_vs_heart[\"k=21\"])\n",
    "error_rate_vs_myknn31 = np.mean(errors_vs_heart[\"k=31\"])\n",
    "\n",
    "# calculate std error rate\n",
    "std_error_rate_vs_myknn1 = np.std(errors_vs_heart[\"k=1\"])\n",
    "std_error_rate_vs_myknn3 = np.std(errors_vs_heart[\"k=3\"])\n",
    "std_error_rate_vs_myknn5 = np.std(errors_vs_heart[\"k=5\"])\n",
    "std_error_rate_vs_myknn11 = np.std(errors_vs_heart[\"k=11\"])\n",
    "std_error_rate_vs_myknn21 = np.std(errors_vs_heart[\"k=21\"])\n",
    "std_error_rate_vs_myknn31 = np.std(errors_vs_heart[\"k=31\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela/Desktop/uam/FAA/faaenv/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# cross-validation (10 folds)\n",
    "vc = ValidacionCruzada(10)\n",
    "\n",
    "errors_vc_heart = {\"k=1\": np.array([]), \"k=3\": np.array([]), \"k=5\": np.array([]), \"k=11\": np.array([]), \"k=21\": np.array([]), \"k=31\": np.array([])}\n",
    "\n",
    "# validate classifiers with heart dataset\n",
    "errors_vc_heart[\"k=1\"] = myknn_1.validacion(vc, heart, myknn_1)\n",
    "errors_vc_heart[\"k=3\"] = myknn_3.validacion(vc, heart, myknn_3)\n",
    "errors_vc_heart[\"k=5\"] = myknn_5.validacion(vc, heart, myknn_5)\n",
    "errors_vc_heart[\"k=11\"] = myknn_11.validacion(vc, heart, myknn_11)\n",
    "errors_vc_heart[\"k=21\"] = myknn_21.validacion(vc, heart, myknn_21)\n",
    "errors_vc_heart[\"k=31\"] = myknn_31.validacion(vc, heart, myknn_31)\n",
    "\n",
    "# calculate mean accuracy\n",
    "accuracy_vc_myknn1 = np.mean(1 - np.array(errors_vc_heart[\"k=1\"]))\n",
    "accuracy_vc_myknn3 = np.mean(1 - np.array(errors_vc_heart[\"k=3\"]))\n",
    "accuracy_vc_myknn5 = np.mean(1 - np.array(errors_vc_heart[\"k=5\"]))\n",
    "accuracy_vc_myknn11 = np.mean(1 - np.array(errors_vc_heart[\"k=11\"]))\n",
    "accuracy_vc_myknn21 = np.mean(1 - np.array(errors_vc_heart[\"k=21\"]))\n",
    "accuracy_vc_myknn31 = np.mean(1 - np.array(errors_vc_heart[\"k=31\"]))\n",
    "\n",
    "# calculate mean error rate\n",
    "error_rate_vc_myknn1 = np.mean(errors_vc_heart[\"k=1\"])\n",
    "error_rate_vc_myknn3 = np.mean(errors_vc_heart[\"k=3\"])\n",
    "error_rate_vc_myknn5 = np.mean(errors_vc_heart[\"k=5\"])\n",
    "error_rate_vc_myknn11 = np.mean(errors_vc_heart[\"k=11\"])\n",
    "error_rate_vc_myknn21 = np.mean(errors_vc_heart[\"k=21\"])\n",
    "error_rate_vc_myknn31 = np.mean(errors_vc_heart[\"k=31\"])\n",
    "\n",
    "# calculate std error rate\n",
    "std_error_rate_vc_myknn1 = np.std(errors_vc_heart[\"k=1\"])\n",
    "std_error_rate_vc_myknn3 = np.std(errors_vc_heart[\"k=3\"])\n",
    "std_error_rate_vc_myknn5 = np.std(errors_vc_heart[\"k=5\"])\n",
    "std_error_rate_vc_myknn11 = np.std(errors_vc_heart[\"k=11\"])\n",
    "std_error_rate_vc_myknn21 = np.std(errors_vc_heart[\"k=21\"])\n",
    "std_error_rate_vc_myknn31 = np.std(errors_vc_heart[\"k=31\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hold-out validation (10 sample)\n",
    "vs = ValidacionSimple(10, 0.3)\n",
    "\n",
    "errors_vs_not_heart = {\"k=1\": np.array([]), \"k=3\": np.array([]), \"k=5\": np.array([]), \"k=11\": np.array([]), \"k=21\": np.array([]), \"k=31\": np.array([])}\n",
    "\n",
    "# validate classifiers with heart dataset\n",
    "errors_vs_not_heart[\"k=1\"] = not_myknn_1.validacion(vs, heart, not_myknn_1)\n",
    "errors_vs_not_heart[\"k=3\"] = not_myknn_3.validacion(vs, heart, not_myknn_3)\n",
    "errors_vs_not_heart[\"k=5\"] = not_myknn_5.validacion(vs, heart, not_myknn_5)\n",
    "errors_vs_not_heart[\"k=11\"] = not_myknn_11.validacion(vs, heart, not_myknn_11)\n",
    "errors_vs_not_heart[\"k=21\"] = not_myknn_21.validacion(vs, heart, not_myknn_21)\n",
    "errors_vs_not_heart[\"k=31\"] = not_myknn_31.validacion(vs, heart, not_myknn_31)\n",
    "\n",
    "# calculate mean accuracy\n",
    "accuracy_vs_not_myknn1 = np.mean(1 - np.array(errors_vs_not_heart[\"k=1\"]))\n",
    "accuracy_vs_not_myknn3 = np.mean(1 - np.array(errors_vs_not_heart[\"k=3\"]))\n",
    "accuracy_vs_not_myknn5 = np.mean(1 - np.array(errors_vs_not_heart[\"k=5\"]))\n",
    "accuracy_vs_not_myknn11 = np.mean(1 - np.array(errors_vs_not_heart[\"k=11\"]))\n",
    "accuracy_vs_not_myknn21 = np.mean(1 - np.array(errors_vs_not_heart[\"k=21\"]))\n",
    "accuracy_vs_not_myknn31 = np.mean(1 - np.array(errors_vs_not_heart[\"k=31\"]))\n",
    "\n",
    "# calculate mean error rate\n",
    "error_rate_vs_not_myknn1 = np.mean(errors_vs_not_heart[\"k=1\"])\n",
    "error_rate_vs_not_myknn3 = np.mean(errors_vs_not_heart[\"k=3\"])\n",
    "error_rate_vs_not_myknn5 = np.mean(errors_vs_not_heart[\"k=5\"])\n",
    "error_rate_vs_not_myknn11 = np.mean(errors_vs_not_heart[\"k=11\"])\n",
    "error_rate_vs_not_myknn21 = np.mean(errors_vs_not_heart[\"k=21\"])\n",
    "error_rate_vs_not_myknn31 = np.mean(errors_vs_not_heart[\"k=31\"])\n",
    "\n",
    "# calculate std error rate\n",
    "std_error_rate_vs_not_myknn1 = np.std(errors_vs_not_heart[\"k=1\"])\n",
    "std_error_rate_vs_not_myknn3 = np.std(errors_vs_not_heart[\"k=3\"])\n",
    "std_error_rate_vs_not_myknn5 = np.std(errors_vs_not_heart[\"k=5\"])\n",
    "std_error_rate_vs_not_myknn11 = np.std(errors_vs_not_heart[\"k=11\"])\n",
    "std_error_rate_vs_not_myknn21 = np.std(errors_vs_not_heart[\"k=21\"])\n",
    "std_error_rate_vs_not_myknn31 = np.std(errors_vs_not_heart[\"k=31\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-validation (10 folds)\n",
    "vc = ValidacionCruzada(10)\n",
    "\n",
    "errors_vc_not_heart = {\"k=1\": np.array([]), \"k=3\": np.array([]), \"k=5\": np.array([]), \"k=11\": np.array([]), \"k=21\": np.array([]), \"k=31\": np.array([])}\n",
    "\n",
    "# validate classifiers with heart dataset\n",
    "errors_vc_not_heart[\"k=1\"] = not_myknn_1.validacion(vc, heart, not_myknn_1)\n",
    "errors_vc_not_heart[\"k=3\"] = not_myknn_3.validacion(vc, heart, not_myknn_3)\n",
    "errors_vc_not_heart[\"k=5\"] = not_myknn_5.validacion(vc, heart, not_myknn_5)\n",
    "errors_vc_not_heart[\"k=11\"] = not_myknn_11.validacion(vc, heart, not_myknn_11)\n",
    "errors_vc_not_heart[\"k=21\"] = not_myknn_21.validacion(vc, heart, not_myknn_21)\n",
    "errors_vc_not_heart[\"k=31\"] = not_myknn_31.validacion(vc, heart, not_myknn_31)\n",
    "\n",
    "# calculate mean accuracy\n",
    "accuracy_vc_not_myknn1 = np.mean(1 - np.array(errors_vc_not_heart[\"k=1\"]))\n",
    "accuracy_vc_not_myknn3 = np.mean(1 - np.array(errors_vc_not_heart[\"k=3\"]))\n",
    "accuracy_vc_not_myknn5 = np.mean(1 - np.array(errors_vc_not_heart[\"k=5\"]))\n",
    "accuracy_vc_not_myknn11 = np.mean(1 - np.array(errors_vc_not_heart[\"k=11\"]))\n",
    "accuracy_vc_not_myknn21 = np.mean(1 - np.array(errors_vc_not_heart[\"k=21\"]))\n",
    "accuracy_vc_not_myknn31 = np.mean(1 - np.array(errors_vc_not_heart[\"k=31\"]))\n",
    "\n",
    "# calculate mean error rate\n",
    "error_rate_vc_not_myknn1 = np.mean(errors_vc_not_heart[\"k=1\"])\n",
    "error_rate_vc_not_myknn3 = np.mean(errors_vc_not_heart[\"k=3\"])\n",
    "error_rate_vc_not_myknn5 = np.mean(errors_vc_not_heart[\"k=5\"])\n",
    "error_rate_vc_not_myknn11 = np.mean(errors_vc_not_heart[\"k=11\"])\n",
    "error_rate_vc_not_myknn21 = np.mean(errors_vc_not_heart[\"k=21\"])\n",
    "error_rate_vc_not_myknn31 = np.mean(errors_vc_not_heart[\"k=31\"])\n",
    "\n",
    "# calculate std error rate\n",
    "std_error_rate_vc_not_myknn1 = np.std(errors_vc_not_heart[\"k=1\"])\n",
    "std_error_rate_vc_not_myknn3 = np.std(errors_vc_not_heart[\"k=3\"])\n",
    "std_error_rate_vc_not_myknn5 = np.std(errors_vc_not_heart[\"k=5\"])\n",
    "std_error_rate_vc_not_myknn11 = np.std(errors_vc_not_heart[\"k=11\"])\n",
    "std_error_rate_vc_not_myknn21 = np.std(errors_vc_not_heart[\"k=21\"])\n",
    "std_error_rate_vc_not_myknn31 = np.std(errors_vc_not_heart[\"k=31\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla de resultados - Heart Dataset (Normalizado)\n",
      "\n",
      "\t\t\t\t\t[Validación Simple]\t\t\t\t[Validación Cruzada]\n",
      "╒═══════════════════════╤════════════╤════════════════╤═══════════════╤═════════════════╤═════════════════════╤════════════════════╕\n",
      "│ K Nearest Neighbors   │   Accuracy │   Error (Mean) │   Error (Std) │   Accuracy - CV │   Error (Mean) - CV │   Error (Std) - CV │\n",
      "╞═══════════════════════╪════════════╪════════════════╪═══════════════╪═════════════════╪═════════════════════╪════════════════════╡\n",
      "│ k=1                   │   0.807273 │       0.192727 │     0.0159337 │        0.801624 │            0.198376 │          0.0430137 │\n",
      "├───────────────────────┼────────────┼────────────────┼───────────────┼─────────────────┼─────────────────────┼────────────────────┤\n",
      "│ k=3                   │   0.826545 │       0.173455 │     0.012964  │        0.825657 │            0.174343 │          0.0368709 │\n",
      "├───────────────────────┼────────────┼────────────────┼───────────────┼─────────────────┼─────────────────────┼────────────────────┤\n",
      "│ k=5                   │   0.841455 │       0.158545 │     0.0179279 │        0.840572 │            0.159428 │          0.0357657 │\n",
      "├───────────────────────┼────────────┼────────────────┼───────────────┼─────────────────┼─────────────────────┼────────────────────┤\n",
      "│ k=11                  │   0.843455 │       0.156545 │     0.0158077 │        0.85645  │            0.14355  │          0.0356004 │\n",
      "├───────────────────────┼────────────┼────────────────┼───────────────┼─────────────────┼─────────────────────┼────────────────────┤\n",
      "│ k=21                  │   0.838764 │       0.161236 │     0.0176596 │        0.847874 │            0.152126 │          0.0373873 │\n",
      "├───────────────────────┼────────────┼────────────────┼───────────────┼─────────────────┼─────────────────────┼────────────────────┤\n",
      "│ k=31                  │   0.837212 │       0.162788 │     0.0193716 │        0.841278 │            0.158722 │          0.0368659 │\n",
      "╘═══════════════════════╧════════════╧════════════════╧═══════════════╧═════════════════╧═════════════════════╧════════════════════╛\n",
      "\n",
      "Tabla de resultados - Heart Dataset (No Normalizado)\n",
      "\n",
      "\t\t\t\t\t[Validación Simple]\t\t\t\t[Validación Cruzada]\n",
      "╒═══════════════════════╤════════════╤════════════════╤═══════════════╤═════════════════╤═════════════════════╤════════════════════╕\n",
      "│ K Nearest Neighbors   │   Accuracy │   Error (Mean) │   Error (Std) │   Accuracy - CV │   Error (Mean) - CV │   Error (Std) - CV │\n",
      "╞═══════════════════════╪════════════╪════════════════╪═══════════════╪═════════════════╪═════════════════════╪════════════════════╡\n",
      "│ k=1                   │   0.654182 │       0.345818 │     0.0286535 │        0.65995  │            0.34005  │          0.0663965 │\n",
      "├───────────────────────┼────────────┼────────────────┼───────────────┼─────────────────┼─────────────────────┼────────────────────┤\n",
      "│ k=3                   │   0.689091 │       0.310909 │     0.0252328 │        0.674791 │            0.325209 │          0.0382834 │\n",
      "├───────────────────────┼────────────┼────────────────┼───────────────┼─────────────────┼─────────────────────┼────────────────────┤\n",
      "│ k=5                   │   0.695515 │       0.304485 │     0.02044   │        0.711272 │            0.288728 │          0.0516901 │\n",
      "├───────────────────────┼────────────┼────────────────┼───────────────┼─────────────────┼─────────────────────┼────────────────────┤\n",
      "│ k=11                  │   0.707091 │       0.292909 │     0.0255058 │        0.711538 │            0.288462 │          0.045129  │\n",
      "├───────────────────────┼────────────┼────────────────┼───────────────┼─────────────────┼─────────────────────┼────────────────────┤\n",
      "│ k=21                  │   0.702182 │       0.297818 │     0.0243853 │        0.708887 │            0.291113 │          0.0464096 │\n",
      "├───────────────────────┼────────────┼────────────────┼───────────────┼─────────────────┼─────────────────────┼────────────────────┤\n",
      "│ k=31                  │   0.70503  │       0.29497  │     0.027758  │        0.710416 │            0.289584 │          0.0483415 │\n",
      "╘═══════════════════════╧════════════╧════════════════╧═══════════════╧═════════════════╧═════════════════════╧════════════════════╛\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "\n",
    "table_heart_myknn = [[\"k=1\", accuracy_vs_myknn1, error_rate_vs_myknn1, std_error_rate_vs_myknn1, accuracy_vc_myknn1, error_rate_vc_myknn1, std_error_rate_vc_myknn1],\n",
    "         [\"k=3\", accuracy_vs_myknn3, error_rate_vs_myknn3, std_error_rate_vs_myknn3, accuracy_vc_myknn3, error_rate_vc_myknn3, std_error_rate_vc_myknn3],\n",
    "         [\"k=5\", accuracy_vs_myknn5, error_rate_vs_myknn5, std_error_rate_vs_myknn5, accuracy_vc_myknn5, error_rate_vc_myknn5, std_error_rate_vc_myknn5],\n",
    "         [\"k=11\", accuracy_vs_myknn11, error_rate_vs_myknn11, std_error_rate_vs_myknn11, accuracy_vc_myknn11, error_rate_vc_myknn11, std_error_rate_vc_myknn11],\n",
    "         [\"k=21\", accuracy_vs_myknn21, error_rate_vs_myknn21, std_error_rate_vs_myknn21, accuracy_vc_myknn21, error_rate_vc_myknn21, std_error_rate_vc_myknn21],\n",
    "         [\"k=31\", accuracy_vs_myknn31, error_rate_vs_myknn31, std_error_rate_vs_myknn31, accuracy_vc_myknn31, error_rate_vc_myknn31, std_error_rate_vc_myknn31]]\n",
    "\n",
    "print(\"Tabla de resultados - Heart Dataset (Normalizado)\\n\")\n",
    "print(\"\\t\\t\\t\\t\\t[Validación Simple]\\t\\t\\t\\t[Validación Cruzada]\")\n",
    "print(tabulate(table_heart_myknn, headers=[\"K Nearest Neighbors\", \"Accuracy\", \"Error (Mean)\", \"Error (Std)\", \"Accuracy - CV\", \"Error (Mean) - CV\", \"Error (Std) - CV\"], tablefmt=\"fancy_grid\"))\n",
    "\n",
    "table_heart_not_myknn = [[\"k=1\", accuracy_vs_not_myknn1, error_rate_vs_not_myknn1, std_error_rate_vs_not_myknn1, accuracy_vc_not_myknn1, error_rate_vc_not_myknn1, std_error_rate_vc_not_myknn1],\n",
    "            [\"k=3\", accuracy_vs_not_myknn3, error_rate_vs_not_myknn3, std_error_rate_vs_not_myknn3, accuracy_vc_not_myknn3, error_rate_vc_not_myknn3, std_error_rate_vc_not_myknn3],\n",
    "            [\"k=5\", accuracy_vs_not_myknn5, error_rate_vs_not_myknn5, std_error_rate_vs_not_myknn5, accuracy_vc_not_myknn5, error_rate_vc_not_myknn5, std_error_rate_vc_not_myknn5],\n",
    "            [\"k=11\", accuracy_vs_not_myknn11, error_rate_vs_not_myknn11, std_error_rate_vs_not_myknn11, accuracy_vc_not_myknn11, error_rate_vc_not_myknn11, std_error_rate_vc_not_myknn11],\n",
    "            [\"k=21\", accuracy_vs_not_myknn21, error_rate_vs_not_myknn21, std_error_rate_vs_not_myknn21, accuracy_vc_not_myknn21, error_rate_vc_not_myknn21, std_error_rate_vc_not_myknn21],\n",
    "            [\"k=31\", accuracy_vs_not_myknn31, error_rate_vs_not_myknn31, std_error_rate_vs_not_myknn31, accuracy_vc_not_myknn31, error_rate_vc_not_myknn31, std_error_rate_vc_not_myknn31]]\n",
    "\n",
    "print(\"\\nTabla de resultados - Heart Dataset (No Normalizado)\\n\")\n",
    "print(\"\\t\\t\\t\\t\\t[Validación Simple]\\t\\t\\t\\t[Validación Cruzada]\")\n",
    "print(tabulate(table_heart_not_myknn, headers=[\"K Nearest Neighbors\", \"Accuracy\", \"Error (Mean)\", \"Error (Std)\", \"Accuracy - CV\", \"Error (Mean) - CV\", \"Error (Std) - CV\"], tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En estas tablas se pueden observar los resultados de ejecutar el clasificador K Nearest Neighbors para diferentes valores de k, con los datos normalizados y no normalizados y con las dos estrategias de particionado. Los resultados obtenidos, son bastante buenos y eso se puede apreciar en el porcentaje de acierto y el de error. En un dataset normalizado, para la mayoría de los valores de k, el porcentaje de error es muy pequeño, por debajo del 20%. Entre la validación simple y la validación cruzada, nos encontramos con el detalle de la práctica anterior y es que la validación cruzada suele dar mejores resultados que la validación simple. Esto se debe a que, al utilizar la validación cruzada, se está utilizando un conjunto de test más grande y el modelo se ajusta mejor. Podemos suponer, que el porcentaje de acierto, que está por encima del 80% pero no llega al 90%, se debe a la distancia elegida para calcular la proximidad entre datos discretizados.\n",
    "\n",
    "\n",
    "Por otro lado, cuando los datos no están normalizados, el porcentaje de error es mayor, llegando a superar el 30% en algunos casos. El contraste entre la validación simple y la cruzada es el mismo que en el caso anterior. En este caso, el porcentaje de acierto es menor que en el caso anterior, llegando a estar por debajo del 70% en muchas ocasiones. Además, es muy notable el hecho de que los datos no estén normalizados observando los valores de la desviación típica del error. Cuando los valores pertenecen a atributos numéricos, el cálculo de la distancia euclídea se ve afectado por la dispersión de los datos y eso se puede apreciar en la variación del procentaje de error.\n",
    "\n",
    "Respecto a los valores de k, se podría decir que cuando k toma un valor muy pequeño (1, 3 o 5), el porcentaje de error es mayor que cuando k toma un valor mayor (11, 21 o 31). Esto se debe a que, cuando k es pequeño, se está sobreajustando el modelo y se está teniendo en cuenta demasiado a los vecinos más cercanos. Por otro lado, cuando k es grande, se está subajustando el modelo y se está teniendo en cuenta a muchos vecinos que no son tan cercanos. Por ello, los valores mínimos de error se suelen encontrar para valores de k intermedios, como 11 o 21."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WDBC Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hold-out validation (10 sample)\n",
    "vs = ValidacionSimple(10, 0.3)\n",
    "\n",
    "errors_vs_wdbc = {\"k=1\": np.array([]), \"k=3\": np.array([]), \"k=5\": np.array([]), \"k=11\": np.array([]), \"k=21\": np.array([]), \"k=31\": np.array([])}\n",
    "\n",
    "# validate classifiers with wdbc dataset\n",
    "errors_vs_wdbc[\"k=1\"] = myknn_1.validacion(vs, wdbc, myknn_1)\n",
    "errors_vs_wdbc[\"k=3\"] = myknn_3.validacion(vs, wdbc, myknn_3)\n",
    "errors_vs_wdbc[\"k=5\"] = myknn_5.validacion(vs, wdbc, myknn_5)\n",
    "errors_vs_wdbc[\"k=11\"] = myknn_11.validacion(vs, wdbc, myknn_11)\n",
    "errors_vs_wdbc[\"k=21\"] = myknn_21.validacion(vs, wdbc, myknn_21)\n",
    "errors_vs_wdbc[\"k=31\"] = myknn_31.validacion(vs, wdbc, myknn_31)\n",
    "\n",
    "# calculate mean accuracy\n",
    "accuracy_vs_myknn1 = np.mean(1 - np.array(errors_vs_wdbc[\"k=1\"]))\n",
    "accuracy_vs_myknn3 = np.mean(1 - np.array(errors_vs_wdbc[\"k=3\"]))\n",
    "accuracy_vs_myknn5 = np.mean(1 - np.array(errors_vs_wdbc[\"k=5\"]))\n",
    "accuracy_vs_myknn11 = np.mean(1 - np.array(errors_vs_wdbc[\"k=11\"]))\n",
    "accuracy_vs_myknn21 = np.mean(1 - np.array(errors_vs_wdbc[\"k=21\"]))\n",
    "accuracy_vs_myknn31 = np.mean(1 - np.array(errors_vs_wdbc[\"k=31\"]))\n",
    "\n",
    "# calculate mean error rate\n",
    "error_rate_vs_myknn1 = np.mean(errors_vs_wdbc[\"k=1\"])\n",
    "error_rate_vs_myknn3 = np.mean(errors_vs_wdbc[\"k=3\"])\n",
    "error_rate_vs_myknn5 = np.mean(errors_vs_wdbc[\"k=5\"])\n",
    "error_rate_vs_myknn11 = np.mean(errors_vs_wdbc[\"k=11\"])\n",
    "error_rate_vs_myknn21 = np.mean(errors_vs_wdbc[\"k=21\"])\n",
    "error_rate_vs_myknn31 = np.mean(errors_vs_wdbc[\"k=31\"])\n",
    "\n",
    "# calculate std error rate\n",
    "std_error_rate_vs_myknn1 = np.std(errors_vs_wdbc[\"k=1\"])\n",
    "std_error_rate_vs_myknn3 = np.std(errors_vs_wdbc[\"k=3\"])\n",
    "std_error_rate_vs_myknn5 = np.std(errors_vs_wdbc[\"k=5\"])\n",
    "std_error_rate_vs_myknn11 = np.std(errors_vs_wdbc[\"k=11\"])\n",
    "std_error_rate_vs_myknn21 = np.std(errors_vs_wdbc[\"k=21\"])\n",
    "std_error_rate_vs_myknn31 = np.std(errors_vs_wdbc[\"k=31\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-validation (10 folds)\n",
    "vc = ValidacionCruzada(10)\n",
    "\n",
    "errors_vc_wdbc = {\"k=1\": np.array([]), \"k=3\": np.array([]), \"k=5\": np.array([]), \"k=11\": np.array([]), \"k=21\": np.array([]), \"k=31\": np.array([])}\n",
    "\n",
    "# validate classifiers with wdbc dataset\n",
    "errors_vc_wdbc[\"k=1\"] = myknn_1.validacion(vc, wdbc, myknn_1)\n",
    "errors_vc_wdbc[\"k=3\"] = myknn_3.validacion(vc, wdbc, myknn_3)\n",
    "errors_vc_wdbc[\"k=5\"] = myknn_5.validacion(vc, wdbc, myknn_5)\n",
    "errors_vc_wdbc[\"k=11\"] = myknn_11.validacion(vc, wdbc, myknn_11)\n",
    "errors_vc_wdbc[\"k=21\"] = myknn_21.validacion(vc, wdbc, myknn_21)\n",
    "errors_vc_wdbc[\"k=31\"] = myknn_31.validacion(vc, wdbc, myknn_31)\n",
    "\n",
    "# calculate mean accuracy\n",
    "accuracy_vc_myknn1 = np.mean(1 - np.array(errors_vc_wdbc[\"k=1\"]))\n",
    "accuracy_vc_myknn3 = np.mean(1 - np.array(errors_vc_wdbc[\"k=3\"]))\n",
    "accuracy_vc_myknn5 = np.mean(1 - np.array(errors_vc_wdbc[\"k=5\"]))\n",
    "accuracy_vc_myknn11 = np.mean(1 - np.array(errors_vc_wdbc[\"k=11\"]))\n",
    "accuracy_vc_myknn21 = np.mean(1 - np.array(errors_vc_wdbc[\"k=21\"]))\n",
    "accuracy_vc_myknn31 = np.mean(1 - np.array(errors_vc_wdbc[\"k=31\"]))\n",
    "\n",
    "# calculate mean error rate\n",
    "error_rate_vc_myknn1 = np.mean(errors_vc_wdbc[\"k=1\"])\n",
    "error_rate_vc_myknn3 = np.mean(errors_vc_wdbc[\"k=3\"])\n",
    "error_rate_vc_myknn5 = np.mean(errors_vc_wdbc[\"k=5\"])\n",
    "error_rate_vc_myknn11 = np.mean(errors_vc_wdbc[\"k=11\"])\n",
    "error_rate_vc_myknn21 = np.mean(errors_vc_wdbc[\"k=21\"])\n",
    "error_rate_vc_myknn31 = np.mean(errors_vc_wdbc[\"k=31\"])\n",
    "\n",
    "# calculate std error rate\n",
    "std_error_rate_vc_myknn1 = np.std(errors_vc_wdbc[\"k=1\"])\n",
    "std_error_rate_vc_myknn3 = np.std(errors_vc_wdbc[\"k=3\"])\n",
    "std_error_rate_vc_myknn5 = np.std(errors_vc_wdbc[\"k=5\"])\n",
    "std_error_rate_vc_myknn11 = np.std(errors_vc_wdbc[\"k=11\"])\n",
    "std_error_rate_vc_myknn21 = np.std(errors_vc_wdbc[\"k=21\"])\n",
    "std_error_rate_vc_myknn31 = np.std(errors_vc_wdbc[\"k=31\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hold-out validation (10 sample)\n",
    "vs = ValidacionSimple(10, 0.3)\n",
    "\n",
    "errors_vs_not_wdbc = {\"k=1\": np.array([]), \"k=3\": np.array([]), \"k=5\": np.array([]), \"k=11\": np.array([]), \"k=21\": np.array([]), \"k=31\": np.array([])}\n",
    "\n",
    "# validate classifiers with wdbc dataset\n",
    "errors_vs_not_wdbc[\"k=1\"] = not_myknn_1.validacion(vs, wdbc, not_myknn_1)\n",
    "errors_vs_not_wdbc[\"k=3\"] = not_myknn_3.validacion(vs, wdbc, not_myknn_3)\n",
    "errors_vs_not_wdbc[\"k=5\"] = not_myknn_5.validacion(vs, wdbc, not_myknn_5)\n",
    "errors_vs_not_wdbc[\"k=11\"] = not_myknn_11.validacion(vs, wdbc, not_myknn_11)\n",
    "errors_vs_not_wdbc[\"k=21\"] = not_myknn_21.validacion(vs, wdbc, not_myknn_21)\n",
    "errors_vs_not_wdbc[\"k=31\"] = not_myknn_31.validacion(vs, wdbc, not_myknn_31)\n",
    "\n",
    "# calculate mean accuracy\n",
    "accuracy_vs_not_myknn1 = np.mean(1 - np.array(errors_vs_not_wdbc[\"k=1\"]))\n",
    "accuracy_vs_not_myknn3 = np.mean(1 - np.array(errors_vs_not_wdbc[\"k=3\"]))\n",
    "accuracy_vs_not_myknn5 = np.mean(1 - np.array(errors_vs_not_wdbc[\"k=5\"]))\n",
    "accuracy_vs_not_myknn11 = np.mean(1 - np.array(errors_vs_not_wdbc[\"k=11\"]))\n",
    "accuracy_vs_not_myknn21 = np.mean(1 - np.array(errors_vs_not_wdbc[\"k=21\"]))\n",
    "accuracy_vs_not_myknn31 = np.mean(1 - np.array(errors_vs_not_wdbc[\"k=31\"]))\n",
    "\n",
    "# calculate mean error rate\n",
    "error_rate_vs_not_myknn1 = np.mean(errors_vs_not_wdbc[\"k=1\"])\n",
    "error_rate_vs_not_myknn3 = np.mean(errors_vs_not_wdbc[\"k=3\"])\n",
    "error_rate_vs_not_myknn5 = np.mean(errors_vs_not_wdbc[\"k=5\"])\n",
    "error_rate_vs_not_myknn11 = np.mean(errors_vs_not_wdbc[\"k=11\"])\n",
    "error_rate_vs_not_myknn21 = np.mean(errors_vs_not_wdbc[\"k=21\"])\n",
    "error_rate_vs_not_myknn31 = np.mean(errors_vs_not_wdbc[\"k=31\"])\n",
    "\n",
    "# calculate std error rate\n",
    "std_error_rate_vs_not_myknn1 = np.std(errors_vs_not_wdbc[\"k=1\"])\n",
    "std_error_rate_vs_not_myknn3 = np.std(errors_vs_not_wdbc[\"k=3\"])\n",
    "std_error_rate_vs_not_myknn5 = np.std(errors_vs_not_wdbc[\"k=5\"])\n",
    "std_error_rate_vs_not_myknn11 = np.std(errors_vs_not_wdbc[\"k=11\"])\n",
    "std_error_rate_vs_not_myknn21 = np.std(errors_vs_not_wdbc[\"k=21\"])\n",
    "std_error_rate_vs_not_myknn31 = np.std(errors_vs_not_wdbc[\"k=31\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-validation (10 folds)\n",
    "vc = ValidacionCruzada(10)\n",
    "\n",
    "errors_vc_not_wdbc = {\"k=1\": np.array([]), \"k=3\": np.array([]), \"k=5\": np.array([]), \"k=11\": np.array([]), \"k=21\": np.array([]), \"k=31\": np.array([])}\n",
    "\n",
    "# validate classifiers with wdbc dataset\n",
    "errors_vc_not_wdbc[\"k=1\"] = not_myknn_1.validacion(vc, wdbc, not_myknn_1)\n",
    "errors_vc_not_wdbc[\"k=3\"] = not_myknn_3.validacion(vc, wdbc, not_myknn_3)\n",
    "errors_vc_not_wdbc[\"k=5\"] = not_myknn_5.validacion(vc, wdbc, not_myknn_5)\n",
    "errors_vc_not_wdbc[\"k=11\"] = not_myknn_11.validacion(vc, wdbc, not_myknn_11)\n",
    "errors_vc_not_wdbc[\"k=21\"] = not_myknn_21.validacion(vc, wdbc, not_myknn_21)\n",
    "errors_vc_not_wdbc[\"k=31\"] = not_myknn_31.validacion(vc, wdbc, not_myknn_31)\n",
    "\n",
    "# calculate mean accuracy\n",
    "accuracy_vc_not_myknn1 = np.mean(1 - np.array(errors_vc_not_wdbc[\"k=1\"]))\n",
    "accuracy_vc_not_myknn3 = np.mean(1 - np.array(errors_vc_not_wdbc[\"k=3\"]))\n",
    "accuracy_vc_not_myknn5 = np.mean(1 - np.array(errors_vc_not_wdbc[\"k=5\"]))\n",
    "accuracy_vc_not_myknn11 = np.mean(1 - np.array(errors_vc_not_wdbc[\"k=11\"]))\n",
    "accuracy_vc_not_myknn21 = np.mean(1 - np.array(errors_vc_not_wdbc[\"k=21\"]))\n",
    "accuracy_vc_not_myknn31 = np.mean(1 - np.array(errors_vc_not_wdbc[\"k=31\"]))\n",
    "\n",
    "# calculate mean error rate\n",
    "error_rate_vc_not_myknn1 = np.mean(errors_vc_not_wdbc[\"k=1\"])\n",
    "error_rate_vc_not_myknn3 = np.mean(errors_vc_not_wdbc[\"k=3\"])\n",
    "error_rate_vc_not_myknn5 = np.mean(errors_vc_not_wdbc[\"k=5\"])\n",
    "error_rate_vc_not_myknn11 = np.mean(errors_vc_not_wdbc[\"k=11\"])\n",
    "error_rate_vc_not_myknn21 = np.mean(errors_vc_not_wdbc[\"k=21\"])\n",
    "error_rate_vc_not_myknn31 = np.mean(errors_vc_not_wdbc[\"k=31\"])\n",
    "\n",
    "# calculate std error rate\n",
    "std_error_rate_vc_not_myknn1 = np.std(errors_vc_not_wdbc[\"k=1\"])\n",
    "std_error_rate_vc_not_myknn3 = np.std(errors_vc_not_wdbc[\"k=3\"])\n",
    "std_error_rate_vc_not_myknn5 = np.std(errors_vc_not_wdbc[\"k=5\"])\n",
    "std_error_rate_vc_not_myknn11 = np.std(errors_vc_not_wdbc[\"k=11\"])\n",
    "std_error_rate_vc_not_myknn21 = np.std(errors_vc_not_wdbc[\"k=21\"])\n",
    "std_error_rate_vc_not_myknn31 = np.std(errors_vc_not_wdbc[\"k=31\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla de resultados - WDBC Dataset (Normalizado)\n",
      "\n",
      "\t\t\t\t\t[Validación Simple]\t\t\t\t[Validación Cruzada]\n",
      "╒═══════════════════════╤════════════╤════════════════╤═══════════════╤═════════════════╤═════════════════════╤════════════════════╕\n",
      "│ K Nearest Neighbors   │   Accuracy │   Error (Mean) │   Error (Std) │   Accuracy - CV │   Error (Mean) - CV │   Error (Std) - CV │\n",
      "╞═══════════════════════╪════════════╪════════════════╪═══════════════╪═════════════════╪═════════════════════╪════════════════════╡\n",
      "│ k=1                   │   0.952353 │      0.0476471 │     0.0158824 │        0.950783 │           0.0492168 │          0.0311985 │\n",
      "├───────────────────────┼────────────┼────────────────┼───────────────┼─────────────────┼─────────────────────┼────────────────────┤\n",
      "│ k=3                   │   0.964118 │      0.0358824 │     0.01175   │        0.965695 │           0.0343045 │          0.0212955 │\n",
      "├───────────────────────┼────────────┼────────────────┼───────────────┼─────────────────┼─────────────────────┼────────────────────┤\n",
      "│ k=5                   │   0.963529 │      0.0364706 │     0.0132755 │        0.967178 │           0.0328216 │          0.0235315 │\n",
      "├───────────────────────┼────────────┼────────────────┼───────────────┼─────────────────┼─────────────────────┼────────────────────┤\n",
      "│ k=11                  │   0.962647 │      0.0373529 │     0.0138922 │        0.967473 │           0.0325266 │          0.0217497 │\n",
      "├───────────────────────┼────────────┼────────────────┼───────────────┼─────────────────┼─────────────────────┼────────────────────┤\n",
      "│ k=21                  │   0.953294 │      0.0467059 │     0.0175057 │        0.954987 │           0.0450125 │          0.0239289 │\n",
      "├───────────────────────┼────────────┼────────────────┼───────────────┼─────────────────┼─────────────────────┼────────────────────┤\n",
      "│ k=31                  │   0.949706 │      0.0502941 │     0.0170292 │        0.951671 │           0.0483292 │          0.0263975 │\n",
      "╘═══════════════════════╧════════════╧════════════════╧═══════════════╧═════════════════╧═════════════════════╧════════════════════╛\n",
      "\n",
      "Tabla de resultados - WDBC Dataset (No Normalizado)\n",
      "\n",
      "\t\t\t\t\t[Validación Simple]\t\t\t\t[Validación Cruzada]\n",
      "╒═══════════════════════╤════════════╤════════════════╤═══════════════╤═════════════════╤═════════════════════╤════════════════════╕\n",
      "│ K Nearest Neighbors   │   Accuracy │   Error (Mean) │   Error (Std) │   Accuracy - CV │   Error (Mean) - CV │   Error (Std) - CV │\n",
      "╞═══════════════════════╪════════════╪════════════════╪═══════════════╪═════════════════╪═════════════════════╪════════════════════╡\n",
      "│ k=1                   │   0.915882 │      0.0841176 │     0.012901  │        0.915695 │           0.0843045 │          0.0310926 │\n",
      "├───────────────────────┼────────────┼────────────────┼───────────────┼─────────────────┼─────────────────────┼────────────────────┤\n",
      "│ k=3                   │   0.924118 │      0.0758824 │     0.0132712 │        0.929731 │           0.0702694 │          0.0318891 │\n",
      "├───────────────────────┼────────────┼────────────────┼───────────────┼─────────────────┼─────────────────────┼────────────────────┤\n",
      "│ k=5                   │   0.92549  │      0.0745098 │     0.0147516 │        0.932091 │           0.0679094 │          0.031297  │\n",
      "├───────────────────────┼────────────┼────────────────┼───────────────┼─────────────────┼─────────────────────┼────────────────────┤\n",
      "│ k=11                  │   0.927059 │      0.0729412 │     0.0159367 │        0.934156 │           0.0658443 │          0.0284382 │\n",
      "├───────────────────────┼────────────┼────────────────┼───────────────┼─────────────────┼─────────────────────┼────────────────────┤\n",
      "│ k=21                  │   0.926118 │      0.0738824 │     0.0169738 │        0.929774 │           0.0702256 │          0.0348682 │\n",
      "├───────────────────────┼────────────┼────────────────┼───────────────┼─────────────────┼─────────────────────┼────────────────────┤\n",
      "│ k=31                  │   0.92049  │      0.0795098 │     0.0165506 │        0.924191 │           0.0758093 │          0.0387506 │\n",
      "╘═══════════════════════╧════════════╧════════════════╧═══════════════╧═════════════════╧═════════════════════╧════════════════════╛\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "\n",
    "table_wdbc_myknn = [[\"k=1\", accuracy_vs_myknn1, error_rate_vs_myknn1, std_error_rate_vs_myknn1, accuracy_vc_myknn1, error_rate_vc_myknn1, std_error_rate_vc_myknn1],\n",
    "         [\"k=3\", accuracy_vs_myknn3, error_rate_vs_myknn3, std_error_rate_vs_myknn3, accuracy_vc_myknn3, error_rate_vc_myknn3, std_error_rate_vc_myknn3],\n",
    "         [\"k=5\", accuracy_vs_myknn5, error_rate_vs_myknn5, std_error_rate_vs_myknn5, accuracy_vc_myknn5, error_rate_vc_myknn5, std_error_rate_vc_myknn5],\n",
    "         [\"k=11\", accuracy_vs_myknn11, error_rate_vs_myknn11, std_error_rate_vs_myknn11, accuracy_vc_myknn11, error_rate_vc_myknn11, std_error_rate_vc_myknn11],\n",
    "         [\"k=21\", accuracy_vs_myknn21, error_rate_vs_myknn21, std_error_rate_vs_myknn21, accuracy_vc_myknn21, error_rate_vc_myknn21, std_error_rate_vc_myknn21],\n",
    "         [\"k=31\", accuracy_vs_myknn31, error_rate_vs_myknn31, std_error_rate_vs_myknn31, accuracy_vc_myknn31, error_rate_vc_myknn31, std_error_rate_vc_myknn31]]\n",
    "\n",
    "print(\"Tabla de resultados - WDBC Dataset (Normalizado)\\n\")\n",
    "print(\"\\t\\t\\t\\t\\t[Validación Simple]\\t\\t\\t\\t[Validación Cruzada]\")\n",
    "print(tabulate(table_wdbc_myknn, headers=[\"K Nearest Neighbors\", \"Accuracy\", \"Error (Mean)\", \"Error (Std)\", \"Accuracy - CV\", \"Error (Mean) - CV\", \"Error (Std) - CV\"], tablefmt=\"fancy_grid\"))\n",
    "\n",
    "table_wdbc_not_myknn = [[\"k=1\", accuracy_vs_not_myknn1, error_rate_vs_not_myknn1, std_error_rate_vs_not_myknn1, accuracy_vc_not_myknn1, error_rate_vc_not_myknn1, std_error_rate_vc_not_myknn1],\n",
    "            [\"k=3\", accuracy_vs_not_myknn3, error_rate_vs_not_myknn3, std_error_rate_vs_not_myknn3, accuracy_vc_not_myknn3, error_rate_vc_not_myknn3, std_error_rate_vc_not_myknn3],\n",
    "            [\"k=5\", accuracy_vs_not_myknn5, error_rate_vs_not_myknn5, std_error_rate_vs_not_myknn5, accuracy_vc_not_myknn5, error_rate_vc_not_myknn5, std_error_rate_vc_not_myknn5],\n",
    "            [\"k=11\", accuracy_vs_not_myknn11, error_rate_vs_not_myknn11, std_error_rate_vs_not_myknn11, accuracy_vc_not_myknn11, error_rate_vc_not_myknn11, std_error_rate_vc_not_myknn11],\n",
    "            [\"k=21\", accuracy_vs_not_myknn21, error_rate_vs_not_myknn21, std_error_rate_vs_not_myknn21, accuracy_vc_not_myknn21, error_rate_vc_not_myknn21, std_error_rate_vc_not_myknn21],\n",
    "            [\"k=31\", accuracy_vs_not_myknn31, error_rate_vs_not_myknn31, std_error_rate_vs_not_myknn31, accuracy_vc_not_myknn31, error_rate_vc_not_myknn31, std_error_rate_vc_not_myknn31]]\n",
    "\n",
    "print(\"\\nTabla de resultados - WDBC Dataset (No Normalizado)\\n\")\n",
    "print(\"\\t\\t\\t\\t\\t[Validación Simple]\\t\\t\\t\\t[Validación Cruzada]\")\n",
    "print(tabulate(table_wdbc_not_myknn, headers=[\"K Nearest Neighbors\", \"Accuracy\", \"Error (Mean)\", \"Error (Std)\", \"Accuracy - CV\", \"Error (Mean) - CV\", \"Error (Std) - CV\"], tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados de ejecutar el clasificador KNN para el dataset WDBC resaltan bastante en comparación con los resultados obtenidos para el dataset Heart. En este caso, el porcentaje de acierto es muy alto, llegando a superar el 90% en algunos casos. Este set de datos está compuesto en su totalidad por atributos numéricos, con lo cual, la distancia euclídea es perfecta para calcular la proximidad entre los datos y no es necesario otro tipo de distancia para atributos discretizados ya que no los hay.\n",
    "\n",
    "Cuando los datos están normalizados, el porcentaje de error es muy pequeño, llegando a estar por debajo del 10% en algunos casos. El uso de la validación simple o cruzada no supone un gran cambio en los datos, ya que el porcentaje de acierto es muy similar en ambos casos. Sin duda, los elevados procentajes de acierto se deben a la normalización de los datos continuos que influyen en el cómputo final de las distancias euclídeas.\n",
    "\n",
    "Por otro lado, cuando los datos no están normalizados, el porcentaje de acierto es ligeramente más pequeño que en el caso anterior, pero sigue rondando el 90%. Como se mencionó antes, la normalización de los datos influye mucho en la dispersión de estos y en el cómputo de las distancias euclídeas. Los k vecinos elegidos pueden no ser los mismos en un set de datos normalizado que en uno no normalizado. No se aprecian apenas diferencias en el uso de validación simple o cruzada ya que ocurre lo mismo que en el caso anterior.\n",
    "\n",
    "Por último, los valores de k influyen en el porcentaje de error de la misma manera que en el caso anterior. Cuando k es muy pequeño, se está sobreajustando el modelo y se está teniendo en cuenta demasiado a los vecinos más cercanos. Por otro lado, cuando k es grande, se está subajustando el modelo y se está teniendo en cuenta a muchos vecinos que no son tan cercanos. Por ello, los valores mínimos de error se suelen encontrar para valores de k intermedios, como 11 o 21."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Algoritmo de clustering K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos el agrupamiento con distintas k, para luego comparar cual se ajusta mejor al problema. De antemano ya conocemos el dataset y sabemos que hay 3 clases de 50 flores cada una, pero probando para cada k queremos comprobar que de hecho k=3, es la que da el mejor comportamiento. A continuación se presentara una breve explicación de como se comporta el algoritmo.\n",
    "\n",
    "## Funcionamiento del algoritmo\n",
    "\n",
    "El algoritmo de K-Means es un algoritmo de agrupamiento, que se encarga de agrupar los datos en k grupos, donde k es un número entero positivo. El algoritmo funciona de la siguiente manera:\n",
    "\n",
    "1. Se eligen k centroides aleatoriamente.\n",
    "2. Se calcula la distancia de cada dato a cada centroide, en este caso decidimos usar la distacnia euclideana que usa la formula: $$euc(x,y) = \\sqrt{\\sum_{i=1}^{n}(x_i-y_i)^2}$$\n",
    "3. Se asigna cada dato al centroide más cercano.\n",
    "4. Se recalcula el centroide de cada grupo usando la media de todos los datos del cluster de determinado centroide.\n",
    "5. Se repiten los pasos 2, 3 y 4 hasta que los centroides no cambien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = [2,3,4,5]\n",
    "\n",
    "# start k_means for each k\n",
    "k_means_2 = K_Means(k[0])\n",
    "k_means_3 = K_Means(k[1])\n",
    "k_means_3_normalized = K_Means(k[1], True)\n",
    "k_means_4 = K_Means(k[2])\n",
    "k_means_5 = K_Means(k[3])\n",
    "\n",
    "# train data\n",
    "k_means_2.train(iris.datos, iris.diccionarios)\n",
    "k_means_3.train(iris.datos, iris.diccionarios)\n",
    "k_means_3_normalized.train(iris.datos, iris.diccionarios)\n",
    "k_means_4.train(iris.datos, iris.diccionarios)\n",
    "k_means_5.train(iris.datos, iris.diccionarios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparación de K-Means con K=2, K=3, K=4, K=5, K=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla de KMeans - K=2, K=3, K=4, K=5\n",
      "╒══════════════╤═══════════════╤═══════════════════╤══════════════════╕\n",
      "│              │   Iris Setosa │   Iris Versicolor │   Iris Virginica │\n",
      "╞══════════════╪═══════════════╪═══════════════════╪══════════════════╡\n",
      "│ KMeans - K=2 │            53 │                97 │                  │\n",
      "├──────────────┼───────────────┼───────────────────┼──────────────────┤\n",
      "│ KMeans - K=3 │            50 │                62 │               38 │\n",
      "├──────────────┼───────────────┼───────────────────┼──────────────────┤\n",
      "│ KMeans - K=4 │            49 │                22 │               34 │\n",
      "├──────────────┼───────────────┼───────────────────┼──────────────────┤\n",
      "│ KMeans - K=5 │            49 │                36 │               18 │\n",
      "╘══════════════╧═══════════════╧═══════════════════╧══════════════════╛\n"
     ]
    }
   ],
   "source": [
    "dicc = {}\n",
    "dicc_normalized = {}\n",
    "dicc_2 = {}\n",
    "dicc_4 = {}\n",
    "dicc_5 = {}\n",
    "# for unormalized\n",
    "for i in range(len(k_means_3.prev_clusters)):\n",
    "    dicc[k_means_3.predicted[i]] = len(k_means_3.prev_clusters[i])\n",
    "\n",
    "# for normalized\n",
    "for i in range(len(k_means_3_normalized.prev_clusters)):\n",
    "    dicc_normalized[k_means_3_normalized.predicted[i]] = len(k_means_3_normalized.prev_clusters[i])\n",
    "\n",
    "# for k = 2\n",
    "for i in range(len(k_means_2.prev_clusters)):\n",
    "    dicc_2[k_means_2.predicted[i]] = len(k_means_2.prev_clusters[i])\n",
    "\n",
    "# for k = 4\n",
    "for i in range(len(k_means_4.prev_clusters)):\n",
    "    dicc_4[k_means_4.predicted[i]] = len(k_means_4.prev_clusters[i])\n",
    "\n",
    "# for k = 5\n",
    "for i in range(len(k_means_5.prev_clusters)):\n",
    "    dicc_5[k_means_5.predicted[i]] = len(k_means_5.prev_clusters[i])\n",
    "\n",
    "table = [[\"KMeans - K=2\", dicc_2[\"Iris-setosa\"], dicc_2[\"Iris-virginica\"]],\n",
    "            [\"KMeans - K=3\", dicc[\"Iris-setosa\"], dicc[\"Iris-versicolor\"], dicc[\"Iris-virginica\"]],\n",
    "            [\"KMeans - K=4\", dicc_4[\"Iris-setosa\"], dicc_4[\"Iris-versicolor\"], dicc_4[\"Iris-virginica\"]],\n",
    "            [\"KMeans - K=5\", dicc_5[\"Iris-setosa\"], dicc_5[\"Iris-versicolor\"], dicc_5[\"Iris-virginica\"]]]\n",
    "\n",
    "print(\"Tabla de KMeans - K=2, K=3, K=4, K=5\")\n",
    "print(tabulate(table, headers=[\"\", \"Iris Setosa\", \"Iris Versicolor\", \"Iris Virginica\"], tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de analizar hacer el kmeans, ya conociamos los datos del Iris dataset. Sabemos que hay 3 clases de 50 flores cada una. K=2 se queda muy corta, debido a que nunca clasifica a una de las flores. K=4, K=5 terminan haciendo muchos clusters que pueden terminar representadno a la misma clase, lo cual no es el comportamiento que buscamos ya que solo queremos un cluster que represente a todas las clases.\n",
    "\n",
    "De las k analizadas la mejor es la 3, que clasifica a la setosa perfectamente. Aunque no clasifica a la versicolor y virginica de manera perfecta, si que lo hace de manera muy buena. Por lo tanto, podemos decir que k=3 es la mejor opción para este dataset. Esto igual se comprueba con la información que teniamos de antemano de nuestro dataset, ya que sabiamos que solo existian 3 clases (setosa, versicolor y virginica)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparación de K-Means con K=3, uno normalizado y otro no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla de KMeans - K=3\n",
      "╒═══════════════════════╤═══════════════╤═══════════════════╤══════════════════╕\n",
      "│                       │   Iris Setosa │   Iris Versicolor │   Iris Virginica │\n",
      "╞═══════════════════════╪═══════════════╪═══════════════════╪══════════════════╡\n",
      "│ Datos no Normalizados │            50 │                62 │               38 │\n",
      "├───────────────────────┼───────────────┼───────────────────┼──────────────────┤\n",
      "│ Datos Normalizados    │            50 │                56 │               44 │\n",
      "╘═══════════════════════╧═══════════════╧═══════════════════╧══════════════════╛\n"
     ]
    }
   ],
   "source": [
    "table = [[\"Datos no Normalizados\", dicc[\"Iris-setosa\"], dicc[\"Iris-versicolor\"], dicc[\"Iris-virginica\"]],\n",
    "            [\"Datos Normalizados\", dicc_normalized[\"Iris-setosa\"], dicc_normalized[\"Iris-versicolor\"], dicc_normalized[\"Iris-virginica\"]]]\n",
    "\n",
    "print(\"Tabla de KMeans - K=3\")\n",
    "print(tabulate(table, headers=[\"\", \"Iris Setosa\", \"Iris Versicolor\", \"Iris Virginica\"], tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comparar la k=3 que sabemos es la mejor con datos normalizados y no normalizados, observamos que siempre se clasifica la Iris Setosa con sus 50 flores. El cambio se ve en las otras dos clases que se confunden entre ellas, pero en el caso de los datos normalizados se confunden menos. Con esto podemos concluir que la normalización de los datos para hacer el agrupamiento puede ayudar a mejorar el algoritmo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flores que se clasifican mejor\n",
    "\n",
    "En las tablas anteriores se oberva como la flor Iris Setosa se clasifica perfectamente en todos los casos en los que k=3. Esto se debe a que la Iris Setosa tiene caracteristicas muy diferentes a las otras dos flores, por lo que es muy facil clasificarla. En cambio, las otras dos flores se confunden entre ellas, ya que tienen caracteristicas muy parecidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Librería de Scikit-Learn para K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide data into train and test (Hold-out)\n",
    "X_heart, y_heart = heart.datos.iloc[:, :-1].values, heart.datos.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create classifiers with different number of neighbours\n",
    "scikit_heart_knn1 = KNeighborsClassifier(n_neighbors=1)\n",
    "scikit_heart_knn3 = KNeighborsClassifier(n_neighbors=3)\n",
    "scikit_heart_knn5 = KNeighborsClassifier(n_neighbors=5)\n",
    "scikit_heart_knn11 = KNeighborsClassifier(n_neighbors=11)\n",
    "scikit_heart_knn21 = KNeighborsClassifier(n_neighbors=21)\n",
    "scikit_heart_knn31 = KNeighborsClassifier(n_neighbors=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hold-out validation (10 samples)\n",
    "\n",
    "num_samples = 10\n",
    "\n",
    "accuracy_scores_heart = {\"k=1\": [], \"k=3\": [], \"k=5\": [], \"k=11\": [], \"k=21\": [], \"k=31\": [] }\n",
    "error_rates_heart = {\"k=1\": [], \"k=3\": [], \"k=5\": [], \"k=11\": [], \"k=21\": [], \"k=31\": [] }\n",
    "\n",
    "for i in range(num_samples):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_heart, y_heart, test_size=0.3)\n",
    "\n",
    "    # train classifiers\n",
    "    scikit_heart_knn1.fit(X_train, y_train)\n",
    "    scikit_heart_knn3.fit(X_train, y_train)\n",
    "    scikit_heart_knn5.fit(X_train, y_train)\n",
    "    scikit_heart_knn11.fit(X_train, y_train)\n",
    "    scikit_heart_knn21.fit(X_train, y_train)\n",
    "    scikit_heart_knn31.fit(X_train, y_train)\n",
    "\n",
    "    # predict test data\n",
    "    y_pred1 = scikit_heart_knn1.predict(X_test)\n",
    "    y_pred3 = scikit_heart_knn3.predict(X_test)\n",
    "    y_pred5 = scikit_heart_knn5.predict(X_test)\n",
    "    y_pred11 = scikit_heart_knn11.predict(X_test)\n",
    "    y_pred21 = scikit_heart_knn21.predict(X_test)\n",
    "    y_pred31 = scikit_heart_knn31.predict(X_test)\n",
    "\n",
    "    # calculate accuracy\n",
    "    accuracy_scores_heart[\"k=1\"].append(accuracy_score(y_test, y_pred1))\n",
    "    accuracy_scores_heart[\"k=3\"].append(accuracy_score(y_test, y_pred3))\n",
    "    accuracy_scores_heart[\"k=5\"].append(accuracy_score(y_test, y_pred5))\n",
    "    accuracy_scores_heart[\"k=11\"].append(accuracy_score(y_test, y_pred11))\n",
    "    accuracy_scores_heart[\"k=21\"].append(accuracy_score(y_test, y_pred21))\n",
    "    accuracy_scores_heart[\"k=31\"].append(accuracy_score(y_test, y_pred31))\n",
    "\n",
    "    # calculate error rate\n",
    "    error_rates_heart[\"k=1\"].append(1 - accuracy_score(y_test, y_pred1))\n",
    "    error_rates_heart[\"k=3\"].append(1 - accuracy_score(y_test, y_pred3))\n",
    "    error_rates_heart[\"k=5\"].append(1 - accuracy_score(y_test, y_pred5))\n",
    "    error_rates_heart[\"k=11\"].append(1 - accuracy_score(y_test, y_pred11))\n",
    "    error_rates_heart[\"k=21\"].append(1 - accuracy_score(y_test, y_pred21))\n",
    "    error_rates_heart[\"k=31\"].append(1 - accuracy_score(y_test, y_pred31))\n",
    "\n",
    "# calculate mean accuracy\n",
    "accuracy_score_knn1 = np.mean(accuracy_scores_heart[\"k=1\"])\n",
    "accuracy_score_knn3 = np.mean(accuracy_scores_heart[\"k=3\"])\n",
    "accuracy_score_knn5 = np.mean(accuracy_scores_heart[\"k=5\"])\n",
    "accuracy_score_knn11 = np.mean(accuracy_scores_heart[\"k=11\"])\n",
    "accuracy_score_knn21 = np.mean(accuracy_scores_heart[\"k=21\"])\n",
    "accuracy_score_knn31 = np.mean(accuracy_scores_heart[\"k=31\"])\n",
    "\n",
    "# calculate mean error rate\n",
    "error_rate_knn1 = np.mean(error_rates_heart[\"k=1\"])\n",
    "error_rate_knn3 = np.mean(error_rates_heart[\"k=3\"])\n",
    "error_rate_knn5 = np.mean(error_rates_heart[\"k=5\"])\n",
    "error_rate_knn11 = np.mean(error_rates_heart[\"k=11\"])\n",
    "error_rate_knn21 = np.mean(error_rates_heart[\"k=21\"])\n",
    "error_rate_knn31 = np.mean(error_rates_heart[\"k=31\"])\n",
    "\n",
    "# calculate std accuracy\n",
    "std_knn1 = np.std(error_rates_heart[\"k=1\"])\n",
    "std_knn3 = np.std(error_rates_heart[\"k=3\"])\n",
    "std_knn5 = np.std(error_rates_heart[\"k=5\"])\n",
    "std_knn11 = np.std(error_rates_heart[\"k=11\"])\n",
    "std_knn21 = np.std(error_rates_heart[\"k=21\"])\n",
    "std_knn31 = np.std(error_rates_heart[\"k=31\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-validation (10 folds)\n",
    "folds = 10\n",
    "\n",
    "# KFold object\n",
    "kf = KFold(n_splits=folds, shuffle=True)\n",
    "\n",
    "accuracy_scores_heart_cv = {\"k=1\": [], \"k=3\": [], \"k=5\": [], \"k=11\": [], \"k=21\": [], \"k=31\": []}\n",
    "error_rates_heart_cv = {\"k=1\": [], \"k=3\": [], \"k=5\": [], \"k=11\": [], \"k=21\": [], \"k=31\": []}\n",
    "\n",
    "for train_index, test_index in kf.split(X_heart):\n",
    "\n",
    "    X_train_cv_heart, X_test_cv_heart = X_heart[train_index], X_heart[test_index]\n",
    "    y_train_cv_heart, y_test_cv_heart = y_heart[train_index], y_heart[test_index]\n",
    "\n",
    "    # train classifiers\n",
    "    scikit_heart_knn1.fit(X_train_cv_heart, y_train_cv_heart)\n",
    "    scikit_heart_knn3.fit(X_train_cv_heart, y_train_cv_heart)\n",
    "    scikit_heart_knn5.fit(X_train_cv_heart, y_train_cv_heart)\n",
    "    scikit_heart_knn11.fit(X_train_cv_heart, y_train_cv_heart)\n",
    "    scikit_heart_knn21.fit(X_train_cv_heart, y_train_cv_heart)\n",
    "    scikit_heart_knn31.fit(X_train_cv_heart, y_train_cv_heart)\n",
    "\n",
    "    y_pred_cv_heart1 = scikit_heart_knn1.predict(X_test_cv_heart)\n",
    "    y_pred_cv_heart3 = scikit_heart_knn3.predict(X_test_cv_heart)\n",
    "    y_pred_cv_heart5 = scikit_heart_knn5.predict(X_test_cv_heart)\n",
    "    y_pred_cv_heart11 = scikit_heart_knn11.predict(X_test_cv_heart)\n",
    "    y_pred_cv_heart21 = scikit_heart_knn21.predict(X_test_cv_heart)\n",
    "    y_pred_cv_heart31 = scikit_heart_knn31.predict(X_test_cv_heart)\n",
    "\n",
    "    # test classifiers\n",
    "    accuracy_scores_heart_cv[\"k=1\"].append(accuracy_score(y_test_cv_heart, y_pred_cv_heart1))\n",
    "    accuracy_scores_heart_cv[\"k=3\"].append(accuracy_score(y_test_cv_heart, y_pred_cv_heart3))\n",
    "    accuracy_scores_heart_cv[\"k=5\"].append(accuracy_score(y_test_cv_heart, y_pred_cv_heart5))\n",
    "    accuracy_scores_heart_cv[\"k=11\"].append(accuracy_score(y_test_cv_heart, y_pred_cv_heart11))\n",
    "    accuracy_scores_heart_cv[\"k=21\"].append(accuracy_score(y_test_cv_heart, y_pred_cv_heart21))\n",
    "    accuracy_scores_heart_cv[\"k=31\"].append(accuracy_score(y_test_cv_heart, y_pred_cv_heart31))\n",
    "\n",
    "    # obtain errors\n",
    "    error_rates_heart_cv[\"k=1\"].append(1-accuracy_score(y_test_cv_heart, y_pred_cv_heart1))\n",
    "    error_rates_heart_cv[\"k=3\"].append(1-accuracy_score(y_test_cv_heart, y_pred_cv_heart3))\n",
    "    error_rates_heart_cv[\"k=5\"].append(1-accuracy_score(y_test_cv_heart, y_pred_cv_heart5))\n",
    "    error_rates_heart_cv[\"k=11\"].append(1-accuracy_score(y_test_cv_heart, y_pred_cv_heart11))\n",
    "    error_rates_heart_cv[\"k=21\"].append(1-accuracy_score(y_test_cv_heart, y_pred_cv_heart21))\n",
    "    error_rates_heart_cv[\"k=31\"].append(1-accuracy_score(y_test_cv_heart, y_pred_cv_heart31))\n",
    "\n",
    "# calculate mean accuracy\n",
    "accuracy_score_knn1_cv = np.mean(accuracy_scores_heart_cv[\"k=1\"])\n",
    "accuracy_score_knn3_cv = np.mean(accuracy_scores_heart_cv[\"k=3\"])\n",
    "accuracy_score_knn5_cv = np.mean(accuracy_scores_heart_cv[\"k=5\"])\n",
    "accuracy_score_knn11_cv = np.mean(accuracy_scores_heart_cv[\"k=11\"])\n",
    "accuracy_score_knn21_cv = np.mean(accuracy_scores_heart_cv[\"k=21\"])\n",
    "accuracy_score_knn31_cv = np.mean(accuracy_scores_heart_cv[\"k=31\"])\n",
    "\n",
    "# calculate mean error rate\n",
    "error_rate_knn1_cv = np.mean(error_rates_heart_cv[\"k=1\"])\n",
    "error_rate_knn3_cv = np.mean(error_rates_heart_cv[\"k=3\"])\n",
    "error_rate_knn5_cv = np.mean(error_rates_heart_cv[\"k=5\"])\n",
    "error_rate_knn11_cv = np.mean(error_rates_heart_cv[\"k=11\"])\n",
    "error_rate_knn21_cv = np.mean(error_rates_heart_cv[\"k=21\"])\n",
    "error_rate_knn31_cv = np.mean(error_rates_heart_cv[\"k=31\"])\n",
    "\n",
    "# calculate std accuracy\n",
    "std_knn1_cv = np.std(error_rates_heart_cv[\"k=1\"])\n",
    "std_knn3_cv = np.std(error_rates_heart_cv[\"k=3\"])\n",
    "std_knn5_cv = np.std(error_rates_heart_cv[\"k=5\"])\n",
    "std_knn11_cv = np.std(error_rates_heart_cv[\"k=11\"])\n",
    "std_knn21_cv = np.std(error_rates_heart_cv[\"k=21\"])\n",
    "std_knn31_cv = np.std(error_rates_heart_cv[\"k=31\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla de resultados - Heart Dataset\n",
      "\n",
      "\t\t\t\t\t[Validación Simple]\t\t\t\t[Validación Cruzada]\n",
      "╒═══════════════════════╤════════════╤════════════════╤═══════════════╤═════════════════╤═════════════════════╤════════════════════╕\n",
      "│ K Nearest Neighbors   │   Accuracy │   Error (Mean) │   Error (Std) │   Accuracy - CV │   Error (Mean) - CV │   Error (Std) - CV │\n",
      "╞═══════════════════════╪════════════╪════════════════╪═══════════════╪═════════════════╪═════════════════════╪════════════════════╡\n",
      "│ k = 1                 │   0.661594 │       0.338406 │     0.0203802 │        0.654623 │            0.345377 │          0.0412381 │\n",
      "├───────────────────────┼────────────┼────────────────┼───────────────┼─────────────────┼─────────────────────┼────────────────────┤\n",
      "│ k = 3                 │   0.683696 │       0.316304 │     0.0300113 │        0.680877 │            0.319123 │          0.043163  │\n",
      "├───────────────────────┼────────────┼────────────────┼───────────────┼─────────────────┼─────────────────────┼────────────────────┤\n",
      "│ k = 5                 │   0.699275 │       0.300725 │     0.0195786 │        0.714632 │            0.285368 │          0.0426531 │\n",
      "├───────────────────────┼────────────┼────────────────┼───────────────┼─────────────────┼─────────────────────┼────────────────────┤\n",
      "│ k = 11                │   0.696014 │       0.303986 │     0.0259987 │        0.717953 │            0.282047 │          0.0399767 │\n",
      "├───────────────────────┼────────────┼────────────────┼───────────────┼─────────────────┼─────────────────────┼────────────────────┤\n",
      "│ k = 21                │   0.705435 │       0.294565 │     0.0230322 │        0.708182 │            0.291818 │          0.0358352 │\n",
      "├───────────────────────┼────────────┼────────────────┼───────────────┼─────────────────┼─────────────────────┼────────────────────┤\n",
      "│ k = 31                │   0.701812 │       0.298188 │     0.0221014 │        0.707059 │            0.292941 │          0.0305966 │\n",
      "╘═══════════════════════╧════════════╧════════════════╧═══════════════╧═════════════════╧═════════════════════╧════════════════════╛\n"
     ]
    }
   ],
   "source": [
    "table_scikit_heart = [[\"k = 1\", accuracy_score_knn1, error_rate_knn1, std_knn1, accuracy_score_knn1_cv, error_rate_knn1_cv, std_knn1_cv],\n",
    "            [\"k = 3\", accuracy_score_knn3, error_rate_knn3, std_knn3, accuracy_score_knn3_cv, error_rate_knn3_cv, std_knn3_cv],\n",
    "            [\"k = 5\", accuracy_score_knn5, error_rate_knn5, std_knn5, accuracy_score_knn5_cv, error_rate_knn5_cv, std_knn5_cv],\n",
    "            [\"k = 11\", accuracy_score_knn11, error_rate_knn11, std_knn11, accuracy_score_knn11_cv, error_rate_knn11_cv, std_knn11_cv],\n",
    "            [\"k = 21\", accuracy_score_knn21, error_rate_knn21, std_knn21, accuracy_score_knn21_cv, error_rate_knn21_cv, std_knn21_cv],\n",
    "            [\"k = 31\", accuracy_score_knn31, error_rate_knn31, std_knn31, accuracy_score_knn31_cv, error_rate_knn31_cv, std_knn31_cv]]\n",
    "\n",
    "print(\"Tabla de resultados - Heart Dataset\\n\")\n",
    "print(\"\\t\\t\\t\\t\\t[Validación Simple]\\t\\t\\t\\t[Validación Cruzada]\")\n",
    "print(tabulate(table_scikit_heart, headers=[\"K Nearest Neighbors\", \"Accuracy\", \"Error (Mean)\", \"Error (Std)\", \"Accuracy - CV\", \"Error (Mean) - CV\", \"Error (Std) - CV\"], tablefmt=\"fancy_grid\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeighborsClassifier es el clasificador de la librería de Scikit-Learn que vamos a usar para clasificar según Vecinos Próximos. Tiene varios argumentos muy interesantes que influyen en el algoritmo a utilizar, como la métrica de distancia o el número de vecinos a utilizar, entre otros. Hemos dejado los valores por defecto para aplicar la distancia euclídea y hemos probados para el mismo número de vecinos que en la primera prueba de nuestro clasificador KNN, es decir, 1, 3, 5, 11, 21 y 31.\n",
    "\n",
    "Recordemos que el dataset de Heart contiene atributos numéricos y categóricos, donde estos últimos siguen una codificación ordinal. Como ya hemos observado antes, la normalización de los datos influye en el resultado final, estando los datos muy dispersos o no. En este caso, los resultados obtenidos por el clasificador de la librería son muy semejantes a los obtenidos por nuestro clasificador con los datos no normalizados y en efecto, los datos proporcionados a este clasificador tampoco están normalizados.\n",
    "\n",
    "Aunque la normalización de los atributos continuos es necesaria, es cierto que la elección de la métrica para los atributos categóricos no es la más adecuada. Tal y como se comentó en la primera prueba de nuestro clasificador, teniendo en cuenta que los atributos nominales están discretizados, la distancia de Hamming sería la más acertada.\n",
    "\n",
    "El porcentaje de error obtenido por el clasificador ronda el 30%, en algunos casos por debajo y en otro superándolo. La diferencia entre estrategias de particionado tampoco es muy notable, sobre todo teniendo en cuenta que la Validación Simple se ejecuta un número dado de veces para poder comparar su ejecución con la Validación Cruzada.\n",
    "\n",
    "En general, el valor elegido de k vuelve a influenciar el procentaje de acierto, siendo los valores intermedios los mejores. Los valores pequeños tienden a sobreajustar el modelo porque se guía demasiado por los vecinos más cercanos y los valores grandes tienden a subajustar el modelo porque se guía por muchos vecinos que no son tan cercanos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WDBC Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide data into train and test (Hold-out)\n",
    "X_wdbc, y_wdbc = wdbc.datos.iloc[:, :-1].values, wdbc.datos.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create classifiers with different number of neighbours\n",
    "scikit_wdbc_knn1 = KNeighborsClassifier(n_neighbors=1)\n",
    "scikit_wdbc_knn3 = KNeighborsClassifier(n_neighbors=3)\n",
    "scikit_wdbc_knn5 = KNeighborsClassifier(n_neighbors=5)\n",
    "scikit_wdbc_knn11 = KNeighborsClassifier(n_neighbors=11)\n",
    "scikit_wdbc_knn21 = KNeighborsClassifier(n_neighbors=21)\n",
    "scikit_wdbc_knn31 = KNeighborsClassifier(n_neighbors=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hold-out validation (10 samples)\n",
    "\n",
    "num_samples = 10\n",
    "\n",
    "accuracy_scores_wdbc = {\"k=1\": [], \"k=3\": [], \"k=5\": [], \"k=11\": [], \"k=21\": [], \"k=31\": [] }\n",
    "error_rates_wdbc = {\"k=1\": [], \"k=3\": [], \"k=5\": [], \"k=11\": [], \"k=21\": [], \"k=31\": [] }\n",
    "\n",
    "for i in range(num_samples):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_wdbc, y_wdbc, test_size=0.3)\n",
    "\n",
    "    # train classifiers\n",
    "    scikit_wdbc_knn1.fit(X_train, y_train)\n",
    "    scikit_wdbc_knn3.fit(X_train, y_train)\n",
    "    scikit_wdbc_knn5.fit(X_train, y_train)\n",
    "    scikit_wdbc_knn11.fit(X_train, y_train)\n",
    "    scikit_wdbc_knn21.fit(X_train, y_train)\n",
    "    scikit_wdbc_knn31.fit(X_train, y_train)\n",
    "\n",
    "    # predict test data\n",
    "    y_pred1 = scikit_wdbc_knn1.predict(X_test)\n",
    "    y_pred3 = scikit_wdbc_knn3.predict(X_test)\n",
    "    y_pred5 = scikit_wdbc_knn5.predict(X_test)\n",
    "    y_pred11 = scikit_wdbc_knn11.predict(X_test)\n",
    "    y_pred21 = scikit_wdbc_knn21.predict(X_test)\n",
    "    y_pred31 = scikit_wdbc_knn31.predict(X_test)\n",
    "\n",
    "    # calculate accuracy\n",
    "    accuracy_scores_wdbc[\"k=1\"].append(accuracy_score(y_test, y_pred1))\n",
    "    accuracy_scores_wdbc[\"k=3\"].append(accuracy_score(y_test, y_pred3))\n",
    "    accuracy_scores_wdbc[\"k=5\"].append(accuracy_score(y_test, y_pred5))\n",
    "    accuracy_scores_wdbc[\"k=11\"].append(accuracy_score(y_test, y_pred11))\n",
    "    accuracy_scores_wdbc[\"k=21\"].append(accuracy_score(y_test, y_pred21))\n",
    "    accuracy_scores_wdbc[\"k=31\"].append(accuracy_score(y_test, y_pred31))\n",
    "\n",
    "    # calculate error rate\n",
    "    error_rates_wdbc[\"k=1\"].append(1 - accuracy_score(y_test, y_pred1))\n",
    "    error_rates_wdbc[\"k=3\"].append(1 - accuracy_score(y_test, y_pred3))\n",
    "    error_rates_wdbc[\"k=5\"].append(1 - accuracy_score(y_test, y_pred5))\n",
    "    error_rates_wdbc[\"k=11\"].append(1 - accuracy_score(y_test, y_pred11))\n",
    "    error_rates_wdbc[\"k=21\"].append(1 - accuracy_score(y_test, y_pred21))\n",
    "    error_rates_wdbc[\"k=31\"].append(1 - accuracy_score(y_test, y_pred31))\n",
    "\n",
    "# calculate mean accuracy\n",
    "accuracy_score_knn1 = np.mean(accuracy_scores_wdbc[\"k=1\"])\n",
    "accuracy_score_knn3 = np.mean(accuracy_scores_wdbc[\"k=3\"])\n",
    "accuracy_score_knn5 = np.mean(accuracy_scores_wdbc[\"k=5\"])\n",
    "accuracy_score_knn11 = np.mean(accuracy_scores_wdbc[\"k=11\"])\n",
    "accuracy_score_knn21 = np.mean(accuracy_scores_wdbc[\"k=21\"])\n",
    "accuracy_score_knn31 = np.mean(accuracy_scores_wdbc[\"k=31\"])\n",
    "\n",
    "# calculate mean error rate\n",
    "error_rate_knn1 = np.mean(error_rates_wdbc[\"k=1\"])\n",
    "error_rate_knn3 = np.mean(error_rates_wdbc[\"k=3\"])\n",
    "error_rate_knn5 = np.mean(error_rates_wdbc[\"k=5\"])\n",
    "error_rate_knn11 = np.mean(error_rates_wdbc[\"k=11\"])\n",
    "error_rate_knn21 = np.mean(error_rates_wdbc[\"k=21\"])\n",
    "error_rate_knn31 = np.mean(error_rates_wdbc[\"k=31\"])\n",
    "\n",
    "# calculate std error rate\n",
    "std_knn1 = np.std(error_rates_wdbc[\"k=1\"])\n",
    "std_knn3 = np.std(error_rates_wdbc[\"k=3\"])\n",
    "std_knn5 = np.std(error_rates_wdbc[\"k=5\"])\n",
    "std_knn11 = np.std(error_rates_wdbc[\"k=11\"])\n",
    "std_knn21 = np.std(error_rates_wdbc[\"k=21\"])\n",
    "std_knn31 = np.std(error_rates_wdbc[\"k=31\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-validation (10 folds)\n",
    "folds = 10\n",
    "\n",
    "# KFold object\n",
    "kf = KFold(n_splits=folds, shuffle=True)\n",
    "\n",
    "accuracy_scores_wdbc_cv = {\"k=1\": [], \"k=3\": [], \"k=5\": [], \"k=11\": [], \"k=21\": [], \"k=31\": []}\n",
    "error_rates_wdbc_cv = {\"k=1\": [], \"k=3\": [], \"k=5\": [], \"k=11\": [], \"k=21\": [], \"k=31\": []}\n",
    "\n",
    "for train_index, test_index in kf.split(X_wdbc):\n",
    "\n",
    "    X_train_cv_wdbc, X_test_cv_wdbc = X_wdbc[train_index], X_wdbc[test_index]\n",
    "    y_train_cv_wdbc, y_test_cv_wdbc = y_wdbc[train_index], y_wdbc[test_index]\n",
    "\n",
    "    # train classifiers\n",
    "    scikit_wdbc_knn1.fit(X_train_cv_wdbc, y_train_cv_wdbc)\n",
    "    scikit_wdbc_knn3.fit(X_train_cv_wdbc, y_train_cv_wdbc)\n",
    "    scikit_wdbc_knn5.fit(X_train_cv_wdbc, y_train_cv_wdbc)\n",
    "    scikit_wdbc_knn11.fit(X_train_cv_wdbc, y_train_cv_wdbc)\n",
    "    scikit_wdbc_knn21.fit(X_train_cv_wdbc, y_train_cv_wdbc)\n",
    "    scikit_wdbc_knn31.fit(X_train_cv_wdbc, y_train_cv_wdbc)\n",
    "\n",
    "    # predict test data\n",
    "    y_pred_cv_wdbc1 = scikit_wdbc_knn1.predict(X_test_cv_wdbc)\n",
    "    y_pred_cv_wdbc3 = scikit_wdbc_knn3.predict(X_test_cv_wdbc)\n",
    "    y_pred_cv_wdbc5 = scikit_wdbc_knn5.predict(X_test_cv_wdbc)\n",
    "    y_pred_cv_wdbc11 = scikit_wdbc_knn11.predict(X_test_cv_wdbc)\n",
    "    y_pred_cv_wdbc21 = scikit_wdbc_knn21.predict(X_test_cv_wdbc)\n",
    "    y_pred_cv_wdbc31 = scikit_wdbc_knn31.predict(X_test_cv_wdbc)\n",
    "\n",
    "    # test classifiers\n",
    "    accuracy_scores_wdbc_cv[\"k=1\"].append(accuracy_score(y_test_cv_wdbc, y_pred_cv_wdbc1))\n",
    "    accuracy_scores_wdbc_cv[\"k=3\"].append(accuracy_score(y_test_cv_wdbc, y_pred_cv_wdbc3))\n",
    "    accuracy_scores_wdbc_cv[\"k=5\"].append(accuracy_score(y_test_cv_wdbc, y_pred_cv_wdbc5))\n",
    "    accuracy_scores_wdbc_cv[\"k=11\"].append(accuracy_score(y_test_cv_wdbc, y_pred_cv_wdbc11))\n",
    "    accuracy_scores_wdbc_cv[\"k=21\"].append(accuracy_score(y_test_cv_wdbc, y_pred_cv_wdbc21))\n",
    "    accuracy_scores_wdbc_cv[\"k=31\"].append(accuracy_score(y_test_cv_wdbc, y_pred_cv_wdbc31))\n",
    "\n",
    "    # obtain errors\n",
    "    error_rates_wdbc_cv[\"k=1\"].append(1-accuracy_score(y_test_cv_wdbc, y_pred_cv_wdbc1))\n",
    "    error_rates_wdbc_cv[\"k=3\"].append(1-accuracy_score(y_test_cv_wdbc, y_pred_cv_wdbc3))\n",
    "    error_rates_wdbc_cv[\"k=5\"].append(1-accuracy_score(y_test_cv_wdbc, y_pred_cv_wdbc5))\n",
    "    error_rates_wdbc_cv[\"k=11\"].append(1-accuracy_score(y_test_cv_wdbc, y_pred_cv_wdbc11))\n",
    "    error_rates_wdbc_cv[\"k=21\"].append(1-accuracy_score(y_test_cv_wdbc, y_pred_cv_wdbc21))\n",
    "    error_rates_wdbc_cv[\"k=31\"].append(1-accuracy_score(y_test_cv_wdbc, y_pred_cv_wdbc31))\n",
    "\n",
    "# calculate mean accuracy\n",
    "accuracy_score_knn1_cv = np.mean(accuracy_scores_wdbc_cv[\"k=1\"])\n",
    "accuracy_score_knn3_cv = np.mean(accuracy_scores_wdbc_cv[\"k=3\"])\n",
    "accuracy_score_knn5_cv = np.mean(accuracy_scores_wdbc_cv[\"k=5\"])\n",
    "accuracy_score_knn11_cv = np.mean(accuracy_scores_wdbc_cv[\"k=11\"])\n",
    "accuracy_score_knn21_cv = np.mean(accuracy_scores_wdbc_cv[\"k=21\"])\n",
    "accuracy_score_knn31_cv = np.mean(accuracy_scores_wdbc_cv[\"k=31\"])\n",
    "\n",
    "# calculate mean error rate\n",
    "error_rate_knn1_cv = np.mean(error_rates_wdbc_cv[\"k=1\"])\n",
    "error_rate_knn3_cv = np.mean(error_rates_wdbc_cv[\"k=3\"])\n",
    "error_rate_knn5_cv = np.mean(error_rates_wdbc_cv[\"k=5\"])\n",
    "error_rate_knn11_cv = np.mean(error_rates_wdbc_cv[\"k=11\"])\n",
    "error_rate_knn21_cv = np.mean(error_rates_wdbc_cv[\"k=21\"])\n",
    "error_rate_knn31_cv = np.mean(error_rates_wdbc_cv[\"k=31\"])\n",
    "\n",
    "# calculate std error rate\n",
    "std_knn1_cv = np.std(error_rates_wdbc_cv[\"k=1\"])\n",
    "std_knn3_cv = np.std(error_rates_wdbc_cv[\"k=3\"])\n",
    "std_knn5_cv = np.std(error_rates_wdbc_cv[\"k=5\"])\n",
    "std_knn11_cv = np.std(error_rates_wdbc_cv[\"k=11\"])\n",
    "std_knn21_cv = np.std(error_rates_wdbc_cv[\"k=21\"])\n",
    "std_knn31_cv = np.std(error_rates_wdbc_cv[\"k=31\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla de resultados - WDBC Dataset\n",
      "\n",
      "\t\t\t\t\t[Validación Simple]\t\t\t\t[Validación Cruzada]\n",
      "╒═══════════════════════╤════════════╤════════════════╤═══════════════╤═════════════════╤═════════════════════╤════════════════════╕\n",
      "│ K Nearest Neighbors   │   Accuracy │   Error (Mean) │   Error (Std) │   Accuracy - CV │   Error (Mean) - CV │   Error (Std) - CV │\n",
      "╞═══════════════════════╪════════════╪════════════════╪═══════════════╪═════════════════╪═════════════════════╪════════════════════╡\n",
      "│ k = 1                 │   0.906433 │      0.0935673 │     0.0135894 │        0.919173 │           0.0808271 │          0.0250078 │\n",
      "├───────────────────────┼────────────┼────────────────┼───────────────┼─────────────────┼─────────────────────┼────────────────────┤\n",
      "│ k = 3                 │   0.92807  │      0.0719298 │     0.0192272 │        0.926222 │           0.0737782 │          0.028001  │\n",
      "├───────────────────────┼────────────┼────────────────┼───────────────┼─────────────────┼─────────────────────┼────────────────────┤\n",
      "│ k = 5                 │   0.927485 │      0.0725146 │     0.0175828 │        0.931516 │           0.0684837 │          0.0276088 │\n",
      "├───────────────────────┼────────────┼────────────────┼───────────────┼─────────────────┼─────────────────────┼────────────────────┤\n",
      "│ k = 11                │   0.925146 │      0.0748538 │     0.0173084 │        0.933271 │           0.0667293 │          0.0280002 │\n",
      "├───────────────────────┼────────────┼────────────────┼───────────────┼─────────────────┼─────────────────────┼────────────────────┤\n",
      "│ k = 21                │   0.918713 │      0.0812865 │     0.0146666 │        0.931516 │           0.0684837 │          0.0354218 │\n",
      "├───────────────────────┼────────────┼────────────────┼───────────────┼─────────────────┼─────────────────────┼────────────────────┤\n",
      "│ k = 31                │   0.910526 │      0.0894737 │     0.0169591 │        0.922744 │           0.0772556 │          0.0343025 │\n",
      "╘═══════════════════════╧════════════╧════════════════╧═══════════════╧═════════════════╧═════════════════════╧════════════════════╛\n"
     ]
    }
   ],
   "source": [
    "table_scikit_wdbc = [[\"k = 1\", accuracy_score_knn1, error_rate_knn1, std_knn1, accuracy_score_knn1_cv, error_rate_knn1_cv, std_knn1_cv],\n",
    "            [\"k = 3\", accuracy_score_knn3, error_rate_knn3, std_knn3, accuracy_score_knn3_cv, error_rate_knn3_cv, std_knn3_cv],\n",
    "            [\"k = 5\", accuracy_score_knn5, error_rate_knn5, std_knn5, accuracy_score_knn5_cv, error_rate_knn5_cv, std_knn5_cv],\n",
    "            [\"k = 11\", accuracy_score_knn11, error_rate_knn11, std_knn11, accuracy_score_knn11_cv, error_rate_knn11_cv, std_knn11_cv],\n",
    "            [\"k = 21\", accuracy_score_knn21, error_rate_knn21, std_knn21, accuracy_score_knn21_cv, error_rate_knn21_cv, std_knn21_cv],\n",
    "            [\"k = 31\", accuracy_score_knn31, error_rate_knn31, std_knn31, accuracy_score_knn31_cv, error_rate_knn31_cv, std_knn31_cv]]\n",
    "\n",
    "print(\"Tabla de resultados - WDBC Dataset\\n\")\n",
    "print(\"\\t\\t\\t\\t\\t[Validación Simple]\\t\\t\\t\\t[Validación Cruzada]\")\n",
    "print(tabulate(table_scikit_wdbc, headers=[\"K Nearest Neighbors\", \"Accuracy\", \"Error (Mean)\", \"Error (Std)\", \"Accuracy - CV\", \"Error (Mean) - CV\", \"Error (Std) - CV\"], tablefmt=\"fancy_grid\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset de WDBC contiene sólo atributos continuos y aunque estos datos no están normalizados, la distancia euclídea es la más adecuada para calcular la proximidad entre los datos. En este caso, los resultados obtenidos por el clasificador de la librería son muy semejantes a los obtenidos por nuestro clasificador con los datos normalizados, superando el 90% de acierto en todos los casos.\n",
    "\n",
    "Esto confirma la suposición planteada antes al probar el clasificador KNN con el dataset Heart, la elección de la distancia para unos atributos u otros influye mucho en el resultado final. Aunque estos datos de WDBC no estén normalizados, la escala de los datos es similar y la distancia euclídea funciona correctamente.\n",
    "\n",
    "Aunque todos los porcentajes de aciertos son muy buenos, se puede apreciar otra vez que los mejores valores de k son los intermedios, como 11. La elección de una estrategia de particionado u otra tampoco influye mucho ya que lso porcentajes de error son muy similares entre ellos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Librería de Scikit-Learn para K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de KMeans - Iris Dataset\n",
      "\n",
      "╒════════════╤════════════╕\n",
      "│ Tipo       │   Cantidad │\n",
      "╞════════════╪════════════╡\n",
      "│ versicolor │         62 │\n",
      "├────────────┼────────────┤\n",
      "│ setosa     │         50 │\n",
      "├────────────┼────────────┤\n",
      "│ virginica  │         38 │\n",
      "╘════════════╧════════════╛\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela/Desktop/uam/FAA/faaenv/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Load the Iris dataset to associate labels easier just for visualization\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "species_names = iris.target_names\n",
    "\n",
    "# k_means with 3 clusters\n",
    "k = 3\n",
    "kmeans = KMeans(n_clusters=k)\n",
    "\n",
    "# use iris data for the clustering\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Get the cluster labels for each data point\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Map cluster labels to iris species names\n",
    "cluster_to_species = {}\n",
    "for cluster in range(k):\n",
    "    cluster_data = iris.target[labels == cluster]\n",
    "    most_common_species = np.argmax(np.bincount(cluster_data))\n",
    "    cluster_species_name = species_names[most_common_species]\n",
    "    cluster_to_species[cluster] = cluster_species_name\n",
    "\n",
    "print(\"Resultados de KMeans - Iris Dataset\\n\")\n",
    "print(tabulate([[cluster_to_species[cluster], np.count_nonzero(labels == cluster)] for cluster in range(k)], headers=[\"Tipo\", \"Cantidad\"], tablefmt=\"fancy_grid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot PCA for iris dataset\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create PCA object\n",
    "pca = PCA(n_components=3)\n",
    "\n",
    "# fit PCA\n",
    "pca.fit(X)\n",
    "\n",
    "# transform data\n",
    "X_pca = pca.transform(X)\n",
    "\n",
    "# plot PCA\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels)\n",
    "plt.title(\"PCA - Iris Dataset\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados presentados por Scikit Learn son los mismos que los que regresa nuestro algoritmo. Ambos clasifican a la setosa de manera perfecta y solo existen problemas en la clasificación de virginica y versicolor. Lo cual es entendible porque tienen valores muy parecidos y el algoritmo no es capaz de diferenciarlos en su totalidad.\n",
    "\n",
    "Además, hemos añadido la gráfica resultante del PCA (Principal  component analysis) para poder visualizar mejor la dispersión de los datos, así como los clusteres que existen el set de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta práctica ha sido muy útil para poder aplicar los conocimientos adquiridos durante las clases de teoría sobre los algoritmos de clasificación de K-NN y clusterización de K-Means. Al implementar por nuestra cuenta los dos algoritmos, hemos podido entender mejor su funcionamiento.\n",
    "\n",
    "Además, al haber utilizado los métodos de la librería de Scikit-Learn, ha sido muy fácil comparar los resultados obtenidos con los nuestros. Hemos llegado a la conclusión que la normalización de los datos numéricos y la elección de la métrica, son los factores más influyentes en la decisión de clasificación o clusterización.\n",
    "\n",
    "El procesamiento de los datos es muy importante para obtener buenos resultados y el tipo de estos también. De esta manera, el dataset de wdbc ha sido el que mejor ha funcionado para ambos algoritmos, ya que todos sus atributos son continuos y la distancia euclídea era la ideal para calcular la proximidad entre los datos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
